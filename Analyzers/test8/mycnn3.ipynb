{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Using cmssw CMSSW_10_1_7\n",
      "[INFO    ] Using numpy 1.14.1\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs_depscipy/3.0-omkpbe5/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "[INFO    ] Using tensorflow 1.5.0\n",
      "Using TensorFlow backend.\n",
      "[INFO    ] Using keras 2.1.4\n",
      "[INFO    ] .. list devices: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456)]\n",
      "[INFO    ] Using scipy 1.0.0\n",
      "[INFO    ] Using sklearn 0.19.2\n"
     ]
    }
   ],
   "source": [
    "from nn_globals import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "superstrip_size = 16\n",
    "\n",
    "from nn_logging import getLogger\n",
    "logger = getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_data(filename):\n",
    "  try:\n",
    "    logger.info('Loading cnn data from {0} ...'.format(filename))\n",
    "    loaded = np.load(filename)\n",
    "    the_image_pixels   = loaded['image_pixels']\n",
    "    the_image_channels = loaded['image_channels']\n",
    "    the_labels         = loaded['labels']\n",
    "    the_parameters     = loaded['parameters']\n",
    "    logger.info('Loaded the images with shape {0},{1}'.format(the_image_pixels.shape, the_image_channels.shape))\n",
    "    logger.info('Loaded the labels with shape {0}'.format(the_labels.shape))\n",
    "    logger.info('Loaded the parameters with shape {0}'.format(the_parameters.shape))\n",
    "  except:\n",
    "    logger.error('Failed to load data from file: {0}'.format(filename))\n",
    "    \n",
    "  assert(the_image_pixels.shape[0] == the_image_channels.shape[0])\n",
    "  assert(the_image_pixels.shape[0] == the_labels.shape[0])\n",
    "  assert(the_image_pixels.shape[0] == the_parameters.shape[0])\n",
    "\n",
    "  return the_image_pixels, the_image_channels, the_labels, the_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO    ] Loading cnn data from ../test7/histos_tbe.17.npz ...\n",
      "[INFO    ] Loaded the images with shape (3535956, 50, 2),(3535956, 50, 3)\n",
      "[INFO    ] Loaded the labels with shape (3535956, 3)\n",
      "[INFO    ] Loaded the parameters with shape (3535956, 3)\n"
     ]
    }
   ],
   "source": [
    "image_pixels, image_channels, labels, parameters = cnn_data(infile_images)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.4\n",
    "shuffle = False\n",
    "\n",
    "(image_pixels_train, image_pixels_test, image_channels_train, image_channels_test, labels_train, labels_test, parameters_train, parameters_test) = train_test_split(image_pixels, image_channels, labels, parameters, test_size=test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "  nentries = 200000\n",
    "  (image_pixels_train, image_pixels_test, image_channels_train, image_channels_test, labels_train, labels_test, parameters_train, parameters_test) = train_test_split(image_pixels[:nentries], image_channels[:nentries], labels[:nentries], parameters[:nentries], test_size=test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imaging(pixels, channels, superstrip_size):\n",
    "  zone_size = 7\n",
    "  m_size = 11\n",
    "  n_size = 5040 // superstrip_size\n",
    "  chn_size = 3\n",
    "  image = np.zeros((m_size*zone_size, n_size, chn_size), dtype=np.float32)\n",
    "  mask = (pixels[:,0] != -99)\n",
    "  image[pixels[mask,0], pixels[mask,1]] = channels[mask]\n",
    "  return image\n",
    "\n",
    "def labeling(labels):\n",
    "  pt_size = 21\n",
    "  phi_size = 128\n",
    "  eta_size = 7\n",
    "  image = np.zeros((pt_size, phi_size, eta_size), dtype=np.float32)\n",
    "  image[labels[0], labels[1], labels[2]] = 1\n",
    "  return image\n",
    "\n",
    "def draw(image, label):\n",
    "  aspect = 'auto'\n",
    "  extent = (0,image.shape[1],0,image.shape[0])\n",
    "  #plt.imshow(image[:,:,0], cmap='viridis', interpolation='none', extent=extent, aspect=aspect)\n",
    "  #plt.show()\n",
    "  #plt.imshow(image[:,:,1], cmap='viridis', interpolation='none', extent=extent, aspect=aspect)\n",
    "  #plt.show()\n",
    "  #plt.imshow(image[:,:,2], cmap='viridis', interpolation='none', extent=extent, aspect=aspect)\n",
    "  #plt.show()\n",
    "  image_2d = np.max(image, axis=-1)\n",
    "  image_2d[np.nonzero(image_2d)] = 1\n",
    "  plt.imshow(image_2d, cmap='viridis', interpolation='none', origin='lower', extent=extent, aspect=aspect)\n",
    "  for y in [11,22,33,44,55,66]:\n",
    "    plt.axhline(y=y,linewidth=1, color='w', alpha=0.4)\n",
    "  plt.show()\n",
    "  print np.where(image_2d)\n",
    "  #label_2d = np.max(label, axis=-1)\n",
    "  label_2d = np.expand_dims(label, axis=-1)  #FIXME\n",
    "  print label_2d.shape\n",
    "  label_2d[np.nonzero(label_2d)] = 1\n",
    "  plt.imshow(label_2d, cmap='viridis', interpolation='none', origin='lower')\n",
    "  plt.show()\n",
    "  print np.where(label_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_imaging(pixels, channels, superstrip_size=superstrip_size):\n",
    "  zone_size = 7\n",
    "  m_size = 11\n",
    "  n_size = 5040 // superstrip_size\n",
    "  chn_size = 3\n",
    "  #image_shape = (m_size*zone_size, n_size, chn_size)\n",
    "  image_shape = (m_size*zone_size, n_size)\n",
    "  #image = tf.ones(image_shape, dtype=tf.float32)\n",
    "  mask = tf.not_equal(pixels[:,0], -99)\n",
    "  indices = tf.boolean_mask(pixels, mask)\n",
    "  values = tf.boolean_mask(channels, mask)\n",
    "  #mask = tf.sparse_to_dense(indices, image_shape, 1, default_value=0, validate_indices=False)\n",
    "  #image = image * tf.cast(mask, dtype=tf.float32)\n",
    "  scatter0 = tf.scatter_nd(indices, values[:,0], image_shape)\n",
    "  scatter1 = tf.scatter_nd(indices, values[:,1], image_shape)\n",
    "  scatter2 = tf.scatter_nd(indices, values[:,2], image_shape)\n",
    "  image = tf.stack([scatter0, scatter1, scatter2], axis=-1)\n",
    "  return image\n",
    "\n",
    "def tf_labeling(labels):\n",
    "  pt_size = 21\n",
    "  phi_size = 128\n",
    "  eta_size = 7\n",
    "  image_shape = (pt_size, phi_size, eta_size)\n",
    "  #image = tf.ones(image_shape, dtype=tf.float32)\n",
    "  indices = tf.reshape(labels, [-1,3])\n",
    "  image = tf.sparse_to_dense(indices, image_shape, 1, default_value=0, validate_indices=False)\n",
    "  #image = image * tf.cast(mask, dtype=tf.float32)\n",
    "  return image\n",
    "\n",
    "def tf_labeling_one_hot(labels):\n",
    "  pt_size = 21\n",
    "  classes = tf.one_hot(labels[0], depth=pt_size)\n",
    "  return classes\n",
    "\n",
    "def tf_labeling_no_one_hot(labels):\n",
    "  classes = labels[0]\n",
    "  return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "\n",
    "sanity_check= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image_pixels_ph   = tf.placeholder(image_pixels_train.dtype, image_pixels_train.shape)\n",
    "  image_channels_ph = tf.placeholder(image_channels_train.dtype, image_channels_train.shape)\n",
    "  labels_ph         = tf.placeholder(labels_train.dtype, labels_train.shape)\n",
    "  parameters_ph     = tf.placeholder(parameters_train.dtype, parameters_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  dataset1 = tf.data.Dataset.from_tensor_slices((image_pixels_ph, image_channels_ph))\n",
    "  dataset1 = dataset1.map(tf_imaging)\n",
    "  dataset2 = tf.data.Dataset.from_tensor_slices((labels_ph))\n",
    "  #dataset2 = dataset2.map(tf_labeling)\n",
    "  dataset2 = dataset2.map(tf_labeling_one_hot)\n",
    "  dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "  print(dataset3.output_types)\n",
    "  print(dataset3.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  #batched_dataset = dataset3.batch(4)\n",
    "  batched_dataset = dataset3.batch(1)\n",
    "  iterator = batched_dataset.make_initializable_iterator()\n",
    "  feed_dict = {image_pixels_ph: image_pixels_train, image_channels_ph: image_channels_train, labels_ph: labels_train}\n",
    "  sess.run(iterator.initializer, feed_dict=feed_dict)\n",
    "\n",
    "  next_element = iterator.get_next()\n",
    "\n",
    "  #print(sess.run(next_element))\n",
    "  #print(sess.run(next_element))\n",
    "  #print(sess.run(next_element))\n",
    "  #print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  import matplotlib as mpl\n",
    "  mpl.rcParams['figure.figsize'] = (10,5)\n",
    "  #mpl.rcParams['axes.labelpad'] = 0\n",
    "  #mpl.rcParams['axes.labelsize'] = 0\n",
    "  #mpl.rcParams['xtick.labelsize'] = 0\n",
    "  #mpl.rcParams['ytick.labelsize'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "  image, label = sess.run(next_element)\n",
    "  draw(image[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data_format, n_rows=28, n_columns=28, n_channels=1, n_classes=10, dropout=0.4):\n",
    "  \"\"\"Model to recognize digits in the MNIST dataset.\n",
    "  Network structure is equivalent to:\n",
    "  https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "  and\n",
    "  https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py\n",
    "  But uses the tf.keras API.\n",
    "  Args:\n",
    "    data_format: Either 'channels_first' or 'channels_last'. 'channels_first' is\n",
    "      typically faster on GPUs while 'channels_last' is typically faster on\n",
    "      CPUs. See\n",
    "      https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "  Returns:\n",
    "    A tf.keras.Model.\n",
    "  \"\"\"\n",
    "  if data_format == 'channels_first':\n",
    "    input_shape = [n_channels, n_rows, n_columns]\n",
    "  else:\n",
    "    assert data_format == 'channels_last'\n",
    "    input_shape = [n_rows, n_columns, n_channels]\n",
    "\n",
    "  l = tf.keras.layers\n",
    "      \n",
    "  # The model consists of a sequential chain of layers, so tf.keras.Sequential\n",
    "  # (a subclass of tf.keras.Model) makes for a compact description.\n",
    "  return tf.keras.Sequential(\n",
    "      [\n",
    "          l.Reshape(\n",
    "              target_shape=input_shape,\n",
    "              input_shape=(n_rows * n_columns,)),\n",
    "          l.Conv2D(\n",
    "              32,\n",
    "              5,\n",
    "              padding='same',\n",
    "              data_format=data_format,\n",
    "              activation=tf.nn.relu),\n",
    "          l.MaxPooling2D(\n",
    "              (2, 2), \n",
    "              (2, 2), \n",
    "              padding='same', \n",
    "              data_format=data_format),\n",
    "          l.Conv2D(\n",
    "              64,\n",
    "              5,\n",
    "              padding='same',\n",
    "              data_format=data_format,\n",
    "              activation=tf.nn.relu),\n",
    "          l.MaxPooling2D(\n",
    "              (2, 2), \n",
    "              (2, 2), \n",
    "              padding='same', \n",
    "              data_format=data_format),\n",
    "          l.Flatten(),\n",
    "          l.Dense(1024, activation=tf.nn.relu),\n",
    "          #l.Dropout(dropout),\n",
    "          l.Dense(n_classes),\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "  \"\"\"The model_fn argument for creating an Estimator.\"\"\"\n",
    "  model = create_model(params['data_format'], params['n_rows'], params['n_columns'], params['n_channels'], params['n_classes'], params['dropout'])\n",
    "  learning_rate = params['learning_rate']\n",
    "  \n",
    "  image = features\n",
    "  if isinstance(image, dict):\n",
    "    image = features['image']\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    #logits = model(image, training=False)\n",
    "    logits = model(image)  # no keyword argument 'training' in tensorflow 1.5\n",
    "    predictions = {\n",
    "        'classes': tf.argmax(logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "    }\n",
    "    # For mode == ModeKeys.PREDICT: required fields are predictions.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.PREDICT,\n",
    "        predictions=predictions,\n",
    "        export_outputs={\n",
    "            'classify': tf.estimator.export.PredictOutput(predictions)\n",
    "        })\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
    "\n",
    "    # If we are running multi-GPU, we need to wrap the optimizer.\n",
    "    if params.get('multi_gpu'):\n",
    "      optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "\n",
    "    #logits = model(image, training=True)\n",
    "    logits = model(image)  # no keyword argument 'training' in tensorflow 1.5\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "        labels=labels, predictions=tf.argmax(logits, axis=1))\n",
    "\n",
    "    # Name tensors to be logged with LoggingTensorHook.\n",
    "    tf.identity(learning_rate, 'learning_rate')\n",
    "    tf.identity(loss, 'cross_entropy')\n",
    "    tf.identity(accuracy[1], name='train_accuracy')\n",
    "\n",
    "    # Save accuracy scalar to Tensorboard output.\n",
    "    tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "\n",
    "    # For mode == ModeKeys.TRAIN: required fields are loss and train_op\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        loss=loss,\n",
    "        train_op=optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step()))\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    #logits = model(image, training=False)\n",
    "    logits = model(image)  # no keyword argument 'training' in tensorflow 1.5\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    # For mode == ModeKeys.EVAL: required field is loss.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        loss=loss,\n",
    "        eval_metric_ops={\n",
    "            'accuracy':\n",
    "                tf.metrics.accuracy(\n",
    "                    labels=labels, predictions=tf.argmax(logits, axis=1)),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.training import training\n",
    "from tensorflow.python.data.ops import dataset_ops\n",
    "\n",
    "class IteratorInitializerHook(training.SessionRunHook):\n",
    "  \"\"\"Hook to initialise data iterator after Session is created.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "      super(IteratorInitializerHook, self).__init__()\n",
    "      self.iterator_initializer_func = None\n",
    "      self.feed_fn = None\n",
    "\n",
    "  def after_create_session(self, session, coord):\n",
    "      \"\"\"Initialise the iterator after the session has been created.\"\"\"\n",
    "      self.iterator_initializer_func(session)\n",
    "\n",
    "class _DatasetInitializerHook(training.SessionRunHook):\n",
    "\n",
    "  def __init__(self, iterator, feed_fn):\n",
    "    self._iterator = iterator\n",
    "    self.feed_fn = feed_fn\n",
    "\n",
    "  def begin(self):\n",
    "    self._initializer = self._iterator.initializer\n",
    "\n",
    "  def after_create_session(self, session, coord):\n",
    "    del coord\n",
    "    session.run(self._initializer, feed_dict=self.feed_fn())\n",
    "\n",
    "# from tensorflow/python/estimator/estimator.py\n",
    "def _get_features_and_labels_from_input_fn(self, input_fn, mode):\n",
    "  \"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\n",
    "  result = self._call_input_fn(input_fn, mode)\n",
    "  input_hooks = []\n",
    "  print self.train_input_hook, self.eval_input_hook\n",
    "  if isinstance(result, dataset_ops.Dataset):\n",
    "    iterator = result.make_initializable_iterator()\n",
    "    #input_hooks.append(_DatasetInitializerHook(iterator))\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      input_hooks.append(_DatasetInitializerHook(iterator, self.train_input_hook.feed_fn))\n",
    "    else:  # mode == tf.estimator.ModeKeys.EVAL\n",
    "      input_hooks.append(_DatasetInitializerHook(iterator, self.eval_input_hook.feed_fn))\n",
    "    result = iterator.get_next()\n",
    "  if isinstance(result, (list, tuple)):\n",
    "    if len(result) != 2:\n",
    "      raise ValueError(\n",
    "          'input_fn should return (feautures, labels) as a len 2 tuple.')\n",
    "    return result[0], result[1], input_hooks\n",
    "  return result, None, input_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 7 * 11\n",
    "n_columns = 5040 // superstrip_size\n",
    "n_channels = 3\n",
    "n_classes = 21\n",
    "dropout = 0.2\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "def run_mnist(flags_obj):\n",
    "  \"\"\"Run MNIST training and eval loop.\n",
    "  Args:\n",
    "    flags_obj: An object containing parsed flag values.\n",
    "  \"\"\"\n",
    "  #model_helpers.apply_clean(flags_obj)\n",
    "  model_function = model_fn\n",
    "  \n",
    "  # Get number of GPUs as defined by the --num_gpus flags and the number of\n",
    "  # GPUs available on the machine.\n",
    "  num_gpus = flags_obj.num_gpus\n",
    "  multi_gpu = num_gpus > 1\n",
    "\n",
    "  if multi_gpu:\n",
    "    # Validate that the batch size can be split into devices.\n",
    "    distribution_utils.per_device_batch_size(flags_obj.batch_size, num_gpus)\n",
    "\n",
    "    # There are two steps required if using multi-GPU: (1) wrap the model_fn,\n",
    "    # and (2) wrap the optimizer. The first happens here, and (2) happens\n",
    "    # in the model_fn itself when the optimizer is defined.\n",
    "    model_function = tf.contrib.estimator.replicate_model_fn(\n",
    "        model_fn, loss_reduction=tf.losses.Reduction.MEAN,\n",
    "        devices=[\"/device:GPU:%d\" % d for d in range(num_gpus)])\n",
    "  \n",
    "  data_format = flags_obj.data_format\n",
    "  mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=model_function,\n",
    "      model_dir=flags_obj.model_dir,\n",
    "      params={\n",
    "          'data_format': data_format,\n",
    "          'multi_gpu': multi_gpu,\n",
    "          'n_rows': n_rows,\n",
    "          'n_columns': n_columns,\n",
    "          'n_channels': n_channels,\n",
    "          'n_classes': n_classes,\n",
    "          'dropout': dropout,\n",
    "          'learning_rate': learning_rate,\n",
    "      })\n",
    "  \n",
    "  \n",
    "  # Set up training and evaluation input functions.\n",
    "  def get_train_input_fn_and_hook():\n",
    "    iterator_initializer_hook = IteratorInitializerHook()\n",
    "    \n",
    "    def train_input_fn():\n",
    "      with tf.name_scope('train_data'):\n",
    "        image_pixels_ph   = tf.placeholder(image_pixels_train.dtype, [None]+list(image_pixels_train.shape[1:]))\n",
    "        image_channels_ph = tf.placeholder(image_channels_train.dtype, [None]+list(image_channels_train.shape[1:]))\n",
    "        labels_ph         = tf.placeholder(labels_train.dtype, [None]+list(labels_train.shape[1:]))\n",
    "        parameters_ph     = tf.placeholder(parameters_train.dtype, [None]+list(parameters_train.shape[1:]))\n",
    "        feed_dict_train   = {image_pixels_ph: image_pixels_train, image_channels_ph: image_channels_train, labels_ph: labels_train}\n",
    "\n",
    "        dataset1 = tf.data.Dataset.from_tensor_slices((image_pixels_ph, image_channels_ph))\n",
    "        dataset1 = dataset1.map(tf_imaging)\n",
    "        dataset2 = tf.data.Dataset.from_tensor_slices((labels_ph))\n",
    "        #dataset2 = dataset2.map(tf_labeling)\n",
    "        dataset2 = dataset2.map(tf_labeling_no_one_hot)\n",
    "        dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "        \n",
    "        # When choosing shuffle buffer sizes, larger sizes result in better\n",
    "        # randomness, while smaller sizes use less memory. MNIST is a small\n",
    "        # enough dataset that we can easily shuffle the full epoch.\n",
    "        ds = dataset3.cache().shuffle(buffer_size=50000).batch(flags_obj.batch_size)\n",
    "\n",
    "        # Iterate through the dataset a set number (`epochs_between_evals`) of times\n",
    "        # during each training session.\n",
    "        ds = ds.repeat(flags_obj.epochs_between_evals)\n",
    "\n",
    "        iterator = ds.make_initializable_iterator()\n",
    "        def _init(sess):\n",
    "          sess.run(iterator.initializer, feed_dict=feed_dict_train)\n",
    "        iterator_initializer_hook.iterator_initializer_func = _init\n",
    "        iterator_initializer_hook.feed_fn = lambda: feed_dict_train\n",
    "        return ds\n",
    "    return train_input_fn, iterator_initializer_hook\n",
    "  \n",
    "  def get_eval_input_fn_and_hook():\n",
    "    iterator_initializer_hook = IteratorInitializerHook()\n",
    "    \n",
    "    def eval_input_fn():\n",
    "      with tf.name_scope('test_data'):\n",
    "        image_pixels_ph   = tf.placeholder(image_pixels_test.dtype, [None]+list(image_pixels_test.shape[1:]))\n",
    "        image_channels_ph = tf.placeholder(image_channels_test.dtype, [None]+list(image_channels_test.shape[1:]))\n",
    "        labels_ph         = tf.placeholder(labels_test.dtype, [None]+list(labels_test.shape[1:]))\n",
    "        parameters_ph     = tf.placeholder(parameters_test.dtype, [None]+list(parameters_test.shape[1:]))\n",
    "        feed_dict_test    = {image_pixels_ph: image_pixels_test, image_channels_ph: image_channels_test, labels_ph: labels_test}\n",
    "\n",
    "        dataset1 = tf.data.Dataset.from_tensor_slices((image_pixels_ph, image_channels_ph))\n",
    "        dataset1 = dataset1.map(tf_imaging)\n",
    "        dataset2 = tf.data.Dataset.from_tensor_slices((labels_ph))\n",
    "        #dataset2 = dataset2.map(tf_labeling)\n",
    "        dataset2 = dataset2.map(tf_labeling_no_one_hot)\n",
    "        dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "        \n",
    "        #ds = dataset3.batch(flags_obj.batch_size).make_one_shot_iterator().get_next()\n",
    "        ds = dataset3.batch(flags_obj.batch_size)\n",
    "\n",
    "        iterator = ds.make_initializable_iterator()\n",
    "        def _init(sess):\n",
    "          sess.run(iterator.initializer, feed_dict=feed_dict_test)\n",
    "        iterator_initializer_hook.iterator_initializer_func = _init\n",
    "        iterator_initializer_hook.feed_fn = lambda: feed_dict_test\n",
    "        return ds\n",
    "    return eval_input_fn, iterator_initializer_hook\n",
    "  \n",
    "  train_input_fn, train_input_hook = get_train_input_fn_and_hook()\n",
    "  \n",
    "  eval_input_fn, eval_input_hook = get_eval_input_fn_and_hook()\n",
    "\n",
    "  # Set up hook that outputs training logs every 100 steps.\n",
    "  train_hooks = get_train_hooks(\n",
    "      flags_obj.hooks, model_dir=flags_obj.model_dir,\n",
    "      batch_size=flags_obj.batch_size)\n",
    "  \n",
    "  eval_hooks = []\n",
    "  \n",
    "  # Patch the function _get_features_and_labels_from_input_fn()\n",
    "  import types\n",
    "  mnist_classifier.train_input_hook = train_input_hook\n",
    "  mnist_classifier.eval_input_hook = eval_input_hook\n",
    "  mnist_classifier._get_features_and_labels_from_input_fn = types.MethodType(_get_features_and_labels_from_input_fn, mnist_classifier)\n",
    "\n",
    "  # Train and evaluate model.\n",
    "  for _ in range(flags_obj.train_epochs // flags_obj.epochs_between_evals):\n",
    "    mnist_classifier.train(input_fn=train_input_fn, hooks=train_hooks)\n",
    "    #eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn, hooks=eval_hooks)\n",
    "    #print('\\nEvaluation results:\\n\\t%s\\n' % eval_results)\n",
    "\n",
    "    #if model_helpers.past_stop_threshold(flags_obj.stop_threshold,\n",
    "    #                                     eval_results['accuracy']):\n",
    "    #  break\n",
    "\n",
    "  # Export the model\n",
    "  if flags_obj.export_dir is not None:\n",
    "    image = tf.placeholder(tf.float32, [None, n_rows, n_columns])\n",
    "    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "        'image': image,\n",
    "    })\n",
    "    mnist_classifier.export_savedmodel(flags_obj.export_dir, input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TENSORS_TO_LOG = dict((x, x) for x in ['learning_rate',\n",
    "                                        'cross_entropy',\n",
    "                                        'train_accuracy'])\n",
    "\n",
    "\n",
    "def get_train_hooks(name_list, use_tpu=False, **kwargs):\n",
    "  \"\"\"Factory for getting a list of TensorFlow hooks for training by name.\n",
    "  Args:\n",
    "    name_list: a list of strings to name desired hook classes. Allowed:\n",
    "      LoggingTensorHook, ProfilerHook, ExamplesPerSecondHook, which are defined\n",
    "      as keys in HOOKS\n",
    "    use_tpu: Boolean of whether computation occurs on a TPU. This will disable\n",
    "      hooks altogether.\n",
    "    **kwargs: a dictionary of arguments to the hooks.\n",
    "  Returns:\n",
    "    list of instantiated hooks, ready to be used in a classifier.train call.\n",
    "  Raises:\n",
    "    ValueError: if an unrecognized name is passed.\n",
    "  \"\"\"\n",
    "\n",
    "  if not name_list:\n",
    "    return []\n",
    "\n",
    "  if use_tpu:\n",
    "    tf.logging.warning(\"hooks_helper received name_list `{}`, but a TPU is \"\n",
    "                       \"specified. No hooks will be used.\".format(name_list))\n",
    "    return []\n",
    "\n",
    "  train_hooks = []\n",
    "  for name in name_list:\n",
    "    hook_name = HOOKS.get(name.strip().lower())\n",
    "    if hook_name is None:\n",
    "      raise ValueError('Unrecognized training hook requested: {}'.format(name))\n",
    "    else:\n",
    "      train_hooks.append(hook_name(**kwargs))\n",
    "\n",
    "  return train_hooks\n",
    "\n",
    "\n",
    "def get_logging_tensor_hook(every_n_iter=100, tensors_to_log=None, **kwargs):  # pylint: disable=unused-argument\n",
    "  \"\"\"Function to get LoggingTensorHook.\n",
    "  Args:\n",
    "    every_n_iter: `int`, print the values of `tensors` once every N local\n",
    "      steps taken on the current worker.\n",
    "    tensors_to_log: List of tensor names or dictionary mapping labels to tensor\n",
    "      names. If not set, log _TENSORS_TO_LOG by default.\n",
    "    **kwargs: a dictionary of arguments to LoggingTensorHook.\n",
    "  Returns:\n",
    "    Returns a LoggingTensorHook with a standard set of tensors that will be\n",
    "    printed to stdout.\n",
    "  \"\"\"\n",
    "  if tensors_to_log is None:\n",
    "    tensors_to_log = _TENSORS_TO_LOG\n",
    "\n",
    "  return tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log,\n",
    "      every_n_iter=every_n_iter)\n",
    "\n",
    "\n",
    "def get_profiler_hook(model_dir, save_steps=1000, **kwargs):  # pylint: disable=unused-argument\n",
    "  \"\"\"Function to get ProfilerHook.\n",
    "  Args:\n",
    "    model_dir: The directory to save the profile traces to.\n",
    "    save_steps: `int`, print profile traces every N steps.\n",
    "    **kwargs: a dictionary of arguments to ProfilerHook.\n",
    "  Returns:\n",
    "    Returns a ProfilerHook that writes out timelines that can be loaded into\n",
    "    profiling tools like chrome://tracing.\n",
    "  \"\"\"\n",
    "  return tf.train.ProfilerHook(save_steps=save_steps, output_dir=model_dir)\n",
    "\n",
    "\n",
    "def get_examples_per_second_hook(every_n_steps=100,\n",
    "                                 batch_size=128,\n",
    "                                 warm_steps=5,\n",
    "                                 **kwargs):  # pylint: disable=unused-argument\n",
    "  \"\"\"Function to get ExamplesPerSecondHook.\n",
    "  Args:\n",
    "    every_n_steps: `int`, print current and average examples per second every\n",
    "      N steps.\n",
    "    batch_size: `int`, total batch size used to calculate examples/second from\n",
    "      global time.\n",
    "    warm_steps: skip this number of steps before logging and running average.\n",
    "    **kwargs: a dictionary of arguments to ExamplesPerSecondHook.\n",
    "  Returns:\n",
    "    Returns a ProfilerHook that writes out timelines that can be loaded into\n",
    "    profiling tools like chrome://tracing.\n",
    "  \"\"\"\n",
    "  return hooks.ExamplesPerSecondHook(\n",
    "      batch_size=batch_size, every_n_steps=every_n_steps,\n",
    "      warm_steps=warm_steps, metric_logger=logger.get_benchmark_logger())\n",
    "\n",
    "\n",
    "def get_logging_metric_hook(tensors_to_log=None,\n",
    "                            every_n_secs=600,\n",
    "                            **kwargs):  # pylint: disable=unused-argument\n",
    "  \"\"\"Function to get LoggingMetricHook.\n",
    "  Args:\n",
    "    tensors_to_log: List of tensor names or dictionary mapping labels to tensor\n",
    "      names. If not set, log _TENSORS_TO_LOG by default.\n",
    "    every_n_secs: `int`, the frequency for logging the metric. Default to every\n",
    "      10 mins.\n",
    "  Returns:\n",
    "    Returns a LoggingMetricHook that saves tensor values in a JSON format.\n",
    "  \"\"\"\n",
    "  if tensors_to_log is None:\n",
    "    tensors_to_log = _TENSORS_TO_LOG\n",
    "  return metric_hook.LoggingMetricHook(\n",
    "      tensors=tensors_to_log,\n",
    "      metric_logger=logger.get_benchmark_logger(),\n",
    "      every_n_secs=every_n_secs)\n",
    "\n",
    "\n",
    "# A dictionary to map one hook name and its corresponding function\n",
    "HOOKS = {\n",
    "    'loggingtensorhook': get_logging_tensor_hook,\n",
    "    'profilerhook': get_profiler_hook,\n",
    "    'examplespersecondhook': get_examples_per_second_hook,\n",
    "    'loggingmetrichook': get_logging_metric_hook,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_dir',\n",
       " 'model_dir',\n",
       " 'train_epochs',\n",
       " 'epochs_between_evals',\n",
       " 'batch_size',\n",
       " 'hooks',\n",
       " 'export_dir',\n",
       " 'data_format']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from absl import flags\n",
    "\n",
    "def define_mnist_flags():\n",
    "  import functools\n",
    "  help_wrap = functools.partial(flags.text_wrap, length=80, indent=\"\",\n",
    "                                firstline_indent=\"\\n\")\n",
    "  \n",
    "  key_flags = []\n",
    "  \n",
    "  flags.DEFINE_string(\n",
    "        name=\"data_dir\", short_name=\"dd\", default=\"/tmp\",\n",
    "        help=help_wrap(\"The location of the input data.\"))\n",
    "  key_flags.append(\"data_dir\")\n",
    "  \n",
    "  flags.DEFINE_string(\n",
    "        name=\"model_dir\", short_name=\"md\", default=\"/tmp\",\n",
    "        help=help_wrap(\"The location of the model checkpoint files.\"))\n",
    "  key_flags.append(\"model_dir\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "        name=\"train_epochs\", short_name=\"te\", default=1,\n",
    "        help=help_wrap(\"The number of epochs used to train.\"))\n",
    "  key_flags.append(\"train_epochs\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "        name=\"epochs_between_evals\", short_name=\"ebe\", default=1,\n",
    "        help=help_wrap(\"The number of training epochs to run between \"\n",
    "                       \"evaluations.\"))\n",
    "  key_flags.append(\"epochs_between_evals\")\n",
    "  \n",
    "  flags.DEFINE_float(\n",
    "        name=\"stop_threshold\", short_name=\"st\",\n",
    "        default=None,\n",
    "        help=help_wrap(\"If passed, training will stop at the earlier of \"\n",
    "                       \"train_epochs and when the evaluation metric is  \"\n",
    "                       \"greater than or equal to stop_threshold.\"))\n",
    "  #key_flags.append(\"stop_threshold\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "        name=\"batch_size\", short_name=\"bs\", default=32,\n",
    "        help=help_wrap(\"Batch size for training and evaluation. When using \"\n",
    "                       \"multiple gpus, this is the global batch size for \"\n",
    "                       \"all devices. For example, if the batch size is 32 \"\n",
    "                       \"and there are 4 GPUs, each GPU will get 8 examples on \"\n",
    "                       \"each step.\"))\n",
    "  key_flags.append(\"batch_size\")\n",
    "  \n",
    "  flags.DEFINE_integer(\n",
    "        name=\"num_gpus\", short_name=\"ng\",\n",
    "        default=1 if tf.test.is_gpu_available() else 0,\n",
    "        help=help_wrap(\n",
    "            \"How many GPUs to use with the DistributionStrategies API. The \"\n",
    "            \"default is 1 if TensorFlow can detect a GPU, and 0 otherwise.\"))\n",
    "  #key_flags.append(\"num_gpus\")\n",
    "  \n",
    "  # Construct a pretty summary of hooks.\n",
    "  hook_list_str = (\n",
    "      u\"\\ufeff  Hook:\\n\" + u\"\\n\".join([u\"\\ufeff    {}\".format(key) for key\n",
    "                                       in HOOKS]))\n",
    "  flags.DEFINE_list(\n",
    "      name=\"hooks\", short_name=\"hk\", default=\"LoggingTensorHook\",\n",
    "      help=help_wrap(\n",
    "          u\"A list of (case insensitive) strings to specify the names of \"\n",
    "          u\"training hooks.\\n{}\\n\\ufeff  Example: `--hooks ProfilerHook,\"\n",
    "          u\"ExamplesPerSecondHook`\\n See official.utils.logs.hooks_helper \"\n",
    "          u\"for details.\".format(hook_list_str))\n",
    "  )\n",
    "  key_flags.append(\"hooks\")\n",
    "  \n",
    "  flags.DEFINE_string(\n",
    "      name=\"export_dir\", short_name=\"ed\", default=None,\n",
    "      help=help_wrap(\"If set, a SavedModel serialization of the model will \"\n",
    "                     \"be exported to this directory at the end of training. \"\n",
    "                     \"See the README for more details and relevant links.\")\n",
    "  )\n",
    "  key_flags.append(\"export_dir\")\n",
    "  \n",
    "  flags.DEFINE_enum(\n",
    "      name=\"data_format\", short_name=\"df\", default=\"channels_last\",\n",
    "      enum_values=[\"channels_first\", \"channels_last\"],\n",
    "      help=help_wrap(\n",
    "            \"A flag to override the data format used in the model. \"\n",
    "            \"channels_first provides a performance boost on GPU but is not \"\n",
    "            \"always compatible with CPU. If left unspecified, the data format \"\n",
    "            \"will be chosen automatically based on whether TensorFlow was \"\n",
    "            \"built for CPU or GPU.\"))\n",
    "  key_flags.append(\"data_format\")\n",
    "  return key_flags\n",
    "\n",
    "def clear_flags():\n",
    "  for name in list(flags.FLAGS):\n",
    "    delattr(flags.FLAGS, name)\n",
    "\n",
    "def set_defaults(**kwargs):\n",
    "  #flags.FLAGS.remove_flag_values(kwargs.keys())\n",
    "  for key, value in kwargs.items():\n",
    "    flags.FLAGS.set_default(name=key, value=value)\n",
    "    \n",
    "clear_flags()\n",
    "define_mnist_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4e28185750>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './mnist_model', '_save_summary_steps': 100}\n",
      "<__main__.IteratorInitializerHook object at 0x7f4e28185590> <__main__.IteratorInitializerHook object at 0x7f4e281850d0>\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./mnist_model/model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into ./mnist_model/model.ckpt.\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 3.0426984, train_accuracy = 0.05\n",
      "INFO:tensorflow:loss = 3.0426984, step = 2\n",
      "INFO:tensorflow:global_step/sec: 0.738691\n",
      "INFO:tensorflow:learning_rate = 1e-04, cross_entropy = 2.9651043, train_accuracy = 0.15 (135.377 sec)\n",
      "INFO:tensorflow:loss = 2.9651043, step = 102 (135.376 sec)\n"
     ]
    }
   ],
   "source": [
    "set_defaults(data_dir='./mnist_data',\n",
    "             model_dir='./mnist_model',\n",
    "             batch_size=50,\n",
    "             train_epochs=1)\n",
    "\n",
    "flags.FLAGS(['lol'])\n",
    "\n",
    "run_mnist(flags.FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print image_pixels_train.dtype, image_pixels_train.shape\n",
    "print image_channels_train.dtype, image_channels_train.shape\n",
    "print labels_train.dtype, labels_train.shape\n",
    "print parameters_train.dtype, parameters_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print image_pixels_test.dtype, image_pixels_test.shape\n",
    "print image_channels_test.dtype, image_channels_test.shape\n",
    "print labels_test.dtype, labels_test.shape\n",
    "print parameters_test.dtype, parameters_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
