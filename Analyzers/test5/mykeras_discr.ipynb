{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using numpy 1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using keras 2.0.5\n",
      "[INFO] Using tensorflow 1.1.0\n",
      "[INFO] Using sklearn 0.18.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2023)\n",
    "import random\n",
    "random.seed(2023)\n",
    "print('[INFO] Using numpy {0}'.format(np.__version__))\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import initializers, regularizers, optimizers, losses\n",
    "K.set_epsilon(1e-08)\n",
    "print('[INFO] Using keras {0}'.format(keras.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print('[INFO] Using tensorflow {0}'.format(tf.__version__))\n",
    "\n",
    "import sklearn\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('[INFO] Using sklearn {0}'.format(sklearn.__version__))\n",
    "\n",
    "#import pandas as pd\n",
    "#import statsmodels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "# Globals\n",
    "nlayers = 12  # 5 (CSC) + 4 (RPC) + 3 (GEM)\n",
    "\n",
    "infile = '../test2/histos_tba.12.npz'\n",
    "\n",
    "infile2 = '../test2/histos_tbd.12.npz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded the variables with shape (566433, 76)\n",
      "[INFO] Loaded the parameters with shape (566433, 3)\n"
     ]
    }
   ],
   "source": [
    "#### Load data ####\n",
    "\n",
    "try:\n",
    "    loaded = np.load(infile)\n",
    "    the_variables = loaded['variables']\n",
    "    the_parameters = loaded['parameters']\n",
    "    at_least_14_GeV = np.abs(the_parameters[:,0]) < (1.0/14)  # at least 14 GeV \n",
    "    the_variables = the_variables[at_least_14_GeV]\n",
    "    the_parameters = the_parameters[at_least_14_GeV]\n",
    "except:\n",
    "    print('[ERROR] Failed to load data from file: {0}'.format(infile))\n",
    "\n",
    "print('[INFO] Loaded the variables with shape {0}'.format(the_variables.shape))\n",
    "print('[INFO] Loaded the parameters with shape {0}'.format(the_parameters.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded the variables with shape (241056, 76)\n",
      "[INFO] Loaded the parameters with shape (241056, 3)\n"
     ]
    }
   ],
   "source": [
    "#### Load data (pileup) ####\n",
    "\n",
    "try:\n",
    "    loaded_2 = np.load(infile2)\n",
    "    the_variables_2 = loaded_2['variables']\n",
    "    only_train_50_percent = the_variables_2.shape[0]//2\n",
    "    the_variables_2 = the_variables_2[only_train_50_percent:]  # 50% events for training\n",
    "    the_parameters_2 = np.zeros((the_variables_2.shape[0], 3), dtype=np.float32)\n",
    "except:\n",
    "    print('[ERROR] Failed to load data from file: {0}'.format(infile2))\n",
    "\n",
    "print('[INFO] Loaded the variables with shape {0}'.format(the_variables_2.shape))\n",
    "print('[INFO] Loaded the parameters with shape {0}'.format(the_parameters_2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "\n",
    "  def __init__(self, x, y, adjust_scale=0):\n",
    "    if x is not None and y is not None:\n",
    "      assert(x.shape[1] == (nlayers * 6) + 4)\n",
    "      assert(y.shape[1] == 3)\n",
    "      assert(x.shape[0] == y.shape[0])\n",
    "\n",
    "      self.nentries = x.shape[0]\n",
    "      self.x_orig  = x\n",
    "      self.y_orig  = y\n",
    "      self.x_copy  = x.copy()\n",
    "      self.y_copy  = y.copy()\n",
    "\n",
    "      # Get views\n",
    "      self.x_phi   = self.x_copy[:, nlayers*0:nlayers*1]\n",
    "      self.x_theta = self.x_copy[:, nlayers*1:nlayers*2]\n",
    "      self.x_bend  = self.x_copy[:, nlayers*2:nlayers*3]\n",
    "      self.x_ring  = self.x_copy[:, nlayers*3:nlayers*4]\n",
    "      self.x_fr    = self.x_copy[:, nlayers*4:nlayers*5]\n",
    "      self.x_mask  = self.x_copy[:, nlayers*5:nlayers*6].astype(np.bool)  # this makes a copy\n",
    "      self.x_road  = self.x_copy[:, nlayers*6:nlayers*7]  # ipt, ieta, iphi, iphi_corr\n",
    "      self.y_pt    = self.y_copy[:, 0]  # q/pT\n",
    "      self.y_phi   = self.y_copy[:, 1]\n",
    "      self.y_eta   = self.y_copy[:, 2]\n",
    "      \n",
    "      # Make event weight\n",
    "      #self.w       = np.ones(self.y_pt.shape, dtype=np.float32)\n",
    "      self.w       = np.abs(self.y_pt)/0.2 + 1.0\n",
    "      \n",
    "      # Straightness & zone\n",
    "      self.x_straightness = self.x_road[:, 0][:, np.newaxis]\n",
    "      self.x_zone         = self.x_road[:, 1][:, np.newaxis]\n",
    "      \n",
    "      # Subtract median phi from hit phis\n",
    "      #self.x_phi_median    = self.x_road[:, 2] * 32 - 16  # multiply by 'quadstrip' unit (4 * 8)\n",
    "      self.x_phi_median    = self.x_road[:, 2] * 16 - 8  # multiply by 'doublestrip' unit (2 * 8)\n",
    "      self.x_phi_median    = self.x_phi_median[:, np.newaxis]\n",
    "      self.x_phi          -= self.x_phi_median\n",
    "      \n",
    "      # Subtract median theta from hit thetas\n",
    "      self.x_theta_median  = np.nanmedian(self.x_theta[:,:5], axis=1)  # CSC only\n",
    "      self.x_theta_median[np.isnan(self.x_theta_median)] = np.nanmedian(self.x_theta[np.isnan(self.x_theta_median)], axis=1)  # use all\n",
    "      self.x_theta_median  = self.x_theta_median[:, np.newaxis]\n",
    "      self.x_theta        -= self.x_theta_median\n",
    "      \n",
    "      # Standard scales\n",
    "      if adjust_scale == 0:  # do not adjust\n",
    "        pass\n",
    "      elif adjust_scale == 1:  # use mean and std\n",
    "        self.x_mean  = np.nanmean(self.x_copy, axis=0)\n",
    "        self.x_std   = np.nanstd(self.x_copy, axis=0)\n",
    "        self.x_std   = self._handle_zero_in_scale(self.x_std)\n",
    "        self.x_copy -= self.x_mean\n",
    "        self.x_copy /= self.x_std\n",
    "      elif adjust_scale == 2:  # adjust by hand\n",
    "        self.x_phi   *= 0.000991  # GE1/1 dphi linear correlation with q/pT\n",
    "        self.x_theta *= (1/12.)   # 12 integer theta units\n",
    "        self.x_bend  *= 0.188082  # ME1/2 bend linear correlation with q/pT\n",
    "        x_ring_tmp    = self.x_ring.astype(np.int32)\n",
    "        x_ring_tmp    = (x_ring_tmp == 1) | (x_ring_tmp == 4)\n",
    "        self.x_ring[x_ring_tmp] = 0  # ring 1,4 -> 0\n",
    "        self.x_ring[~x_ring_tmp] = 1 # ring 2,3 -> 1\n",
    "        #self.x_fr     = self.x_fr\n",
    "      \n",
    "      # Remove outlier hits by checking hit thetas\n",
    "      if adjust_scale == 0:  # do not adjust\n",
    "        x_theta_tmp = np.abs(self.x_theta) > 10000.0\n",
    "      elif adjust_scale == 1:  # use mean and std\n",
    "        x_theta_tmp = np.abs(self.x_theta) > 1.0\n",
    "      elif adjust_scale == 2:  # adjust by hand\n",
    "        theta_cuts    = np.array((6., 6., 6., 6., 6., 12., 12., 12., 12., 9., 9., 9.), dtype=np.float32)\n",
    "        theta_cuts   *= (1/12.)   # 12 integer theta units\n",
    "        assert(len(theta_cuts) == nlayers)\n",
    "        x_theta_tmp = np.abs(self.x_theta) > theta_cuts\n",
    "      self.x_phi  [x_theta_tmp] = np.nan\n",
    "      self.x_theta[x_theta_tmp] = np.nan\n",
    "      self.x_bend [x_theta_tmp] = np.nan\n",
    "      self.x_ring [x_theta_tmp] = np.nan\n",
    "      self.x_fr   [x_theta_tmp] = np.nan\n",
    "      self.x_mask [x_theta_tmp] = 1.0\n",
    "      \n",
    "      # Add variables: straightness, zone, theta_median and mode variables\n",
    "      self.x_straightness -= 6.  # scaled to [-1,1]\n",
    "      self.x_straightness /= 6.\n",
    "      self.x_zone         -= 0.  # scaled to [0,1]\n",
    "      self.x_zone         /= 5.\n",
    "      self.x_theta_median -= 3.  # scaled to [0,1]\n",
    "      self.x_theta_median /= 83.\n",
    "      hits_to_station = np.array((5,1,2,3,4,1,2,3,4,5,2,5), dtype=np.int32)  # '5' denotes ME1/1\n",
    "      assert(len(hits_to_station) == nlayers)\n",
    "      self.x_mode_vars = np.zeros((self.nentries, 5), dtype=np.bool)\n",
    "      self.x_mode_vars[:,0] = np.any(self.x_mask[:,hits_to_station == 5] == 0, axis=1)\n",
    "      self.x_mode_vars[:,1] = np.any(self.x_mask[:,hits_to_station == 1] == 0, axis=1)\n",
    "      self.x_mode_vars[:,2] = np.any(self.x_mask[:,hits_to_station == 2] == 0, axis=1)\n",
    "      self.x_mode_vars[:,3] = np.any(self.x_mask[:,hits_to_station == 3] == 0, axis=1)\n",
    "      self.x_mode_vars[:,4] = np.any(self.x_mask[:,hits_to_station == 4] == 0, axis=1)\n",
    "      \n",
    "      # Remove NaN\n",
    "      #np.nan_to_num(self.x_copy, copy=False)\n",
    "      self.x_copy[np.isnan(self.x_copy)] = 0.0\n",
    "\n",
    "  # Copied from scikit-learn\n",
    "  def _handle_zero_in_scale(self, scale):\n",
    "    scale[scale == 0.0] = 1.0\n",
    "    return scale\n",
    "\n",
    "  def get_x(self):\n",
    "    #x_new = self.x_phi\n",
    "    x_new = np.hstack((self.x_phi, self.x_theta, self.x_bend, self.x_ring, self.x_fr, self.x_straightness, self.x_zone, self.x_theta_median, self.x_mode_vars))\n",
    "    return x_new\n",
    "\n",
    "  def get_x_mask(self):\n",
    "    x_mask = self.x_mask.copy()\n",
    "    return x_mask\n",
    "\n",
    "  def get_y(self):\n",
    "    y_new = self.y_pt.copy()\n",
    "    return y_new\n",
    "\n",
    "  def get_w(self):\n",
    "    w_new = self.w.copy()\n",
    "    return w_new\n",
    "\n",
    "  def save_encoder(self, filepath):\n",
    "    np.savez_compressed(filepath, x_mean=self.x_mean, x_std=self.x_std)\n",
    "\n",
    "  def load_endcoder(self, filepath):\n",
    "    loaded = np.load(filepath)\n",
    "    self.x_mean = loaded['x_mean']\n",
    "    self.x_std = loaded['x_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-numpy/1.12.1-mlhled2/lib/python2.7/site-packages/numpy-1.12.1-py2.7-linux-x86_64.egg/numpy/lib/function_base.py:3858: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs/5.0-ghjeda6/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using 68 variables and 1 parameters\n"
     ]
    }
   ],
   "source": [
    "#### Prepare data ####\n",
    "\n",
    "# Preprocess data\n",
    "encoder_1 = Encoder(the_variables, the_parameters, adjust_scale=2)\n",
    "x_1, y_1, w_1, x_mask_1 = encoder_1.get_x(), encoder_1.get_y(), encoder_1.get_w(), encoder_1.get_x_mask()\n",
    "#encoder.save_encoder('encoder.npz')\n",
    "#print('[INFO] Encoder is saved as encoder.npz')\n",
    "\n",
    "# Split dataset in training and testing\n",
    "x_train_1, x_test_1, y_train_1, y_test_1, w_train_1, w_test_1, x_mask_train_1, x_mask_test_1 = train_test_split(x_1, y_1, w_1, x_mask_1, test_size=0.4)\n",
    "\n",
    "nvariables = x_train_1.shape[1]\n",
    "nparameters = 1\n",
    "print('[INFO] Using {0} variables and {1} parameters'.format(nvariables, nparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        0.007928  0.003964 ...,  1.        1.        1.      ]\n",
      " [ 0.       -0.003964  0.       ...,  1.        1.        1.      ]\n",
      " [ 0.038649  0.        0.       ...,  1.        1.        1.      ]\n",
      " ..., \n",
      " [ 0.        0.007928 -0.007928 ...,  1.        1.        1.      ]\n",
      " [ 0.03964   0.        0.       ...,  1.        1.        1.      ]\n",
      " [ 0.044595  0.       -0.007928 ...,  1.        1.        1.      ]] [ 0.01238597 -0.00417533  0.06883084 ...,  0.04690636  0.06029635\n",
      "  0.05258178] [ 1.06192982  1.02087665  1.34415424 ...,  1.23453176  1.30148172\n",
      "  1.26290894]\n",
      "[ -1.67510216e-03  -9.86234634e-04  -2.49763578e-03  -2.60640611e-03\n",
      "  -2.58804532e-03  -7.88200065e-04  -8.35446059e-04  -2.21028528e-03\n",
      "  -2.32811854e-03  -1.17528578e-03  -1.16607826e-03   0.00000000e+00\n",
      "   2.69002561e-02   2.12615356e-03  -2.47679185e-04  -9.33684222e-03\n",
      "  -1.76106137e-03  -8.65412503e-03  -2.56192777e-03   2.47557787e-03\n",
      "   1.98716298e-02   1.57528631e-02   2.37430353e-02   0.00000000e+00\n",
      "  -6.50801085e-05   1.74656307e-04  -3.32707801e-04  -4.26013576e-04\n",
      "  -3.67906177e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   3.14753920e-01   9.99682248e-01   3.67284387e-01   4.68765050e-01\n",
      "   5.45319557e-01   9.99593973e-01   9.99973536e-01   5.53837776e-01\n",
      "   6.03993773e-01   5.44242680e-01   5.44941783e-01   1.00000000e+00\n",
      "   3.44268441e-01   1.31683707e-01   4.49477702e-01   4.41605628e-01\n",
      "   4.36966062e-01   1.15049794e-01   1.20384932e-01   4.81852233e-01\n",
      "   4.82062310e-01   2.37913400e-01   2.28480682e-01   0.00000000e+00\n",
      "  -4.69796592e-03   4.66884941e-01   4.21638459e-01   7.01786458e-01\n",
      "   2.97969937e-01   9.45294499e-01   9.81856644e-01   9.84626591e-01]\n",
      "[ 0.03451658  0.0087275   0.01361463  0.01598009  0.01745525  0.0078904\n",
      "  0.00573708  0.01735244  0.01898063  0.03606134  0.01236981  0.          0.0511788\n",
      "  0.02223346  0.02855504  0.03235305  0.02994239  0.17312315  0.14122422\n",
      "  0.19753745  0.18744755  0.0758219   0.07880225  0.          0.09071632\n",
      "  0.0547306   0.0856449   0.09024934  0.09107859  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.46479279  0.01782069\n",
      "  0.48111644  0.49827886  0.4967635   0.02014262  0.00514588  0.4961746\n",
      "  0.48904192  0.49881807  0.49874705  0.          0.47438693  0.33716524\n",
      "  0.49814752  0.4967216   0.49556649  0.31826568  0.32580262  0.49943206\n",
      "  0.49943253  0.42446682  0.41999811  0.          0.09510344  0.35590175\n",
      "  0.26511246  0.45662555  0.45633835  0.22822644  0.13341197  0.12256206]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print x_1, y_1, w_1\n",
    "print np.mean(x_1, axis=0)\n",
    "print np.std(x_1, axis=0)\n",
    "print np.isfinite(x_1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs/5.0-ghjeda6/lib/python2.7/site-packages/ipykernel_launcher.py:75: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using 68 variables and 1 parameters\n"
     ]
    }
   ],
   "source": [
    "#### Prepare data (pileup) ####\n",
    "\n",
    "# Preprocess data\n",
    "encoder_2 = Encoder(the_variables_2, the_parameters_2, adjust_scale=2)\n",
    "x_2, y_2, w_2, x_mask_2 = encoder_2.get_x(), encoder_2.get_y(), encoder_2.get_w(), encoder_2.get_x_mask()\n",
    "#encoder.save_encoder('encoder.npz')\n",
    "#print('[INFO] Encoder is saved as encoder.npz')\n",
    "\n",
    "# Split dataset in training and testing\n",
    "x_train_2, x_test_2, y_train_2, y_test_2, w_train_2, w_test_2, x_mask_train_2, x_mask_test_2 = train_test_split(x_2, y_2, w_2, x_mask_2, test_size=0.0)  # no train/test split\n",
    "\n",
    "nvariables = x_train_2.shape[1]\n",
    "nparameters = 1\n",
    "print('[INFO] Using {0} variables and {1} parameters'.format(nvariables, nparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19919099  0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.26756999  0.          0.         ...,  1.          1.          0.        ]\n",
      " [ 0.         -0.045586    0.         ...,  0.          1.          1.        ]\n",
      " ..., \n",
      " [ 0.         -0.004955   -0.072343   ...,  1.          1.          1.        ]\n",
      " [-0.342886    0.          0.11892    ...,  1.          1.          0.        ]\n",
      " [ 0.          0.028739    0.067388   ...,  1.          1.          1.        ]] [ 0.  0.  0. ...,  0.  0.  0.] [ 1.  1.  1. ...,  1.  1.  1.]\n",
      "[  6.09499868e-03  -6.07257592e-04  -4.26684087e-03  -4.06896928e-03\n",
      "  -4.92226332e-03  -8.14288913e-04  -1.77615177e-04  -5.93110733e-03\n",
      "  -4.70448099e-03   1.91887806e-03  -2.83443625e-03   0.00000000e+00\n",
      "   9.36241895e-02   2.29961146e-02  -5.64891752e-03  -3.09543181e-02\n",
      "  -4.00824994e-02   3.34567130e-02   1.22885974e-02  -9.76139233e-02\n",
      "  -3.72858457e-02   3.05461772e-02   2.10950170e-02   0.00000000e+00\n",
      "   8.15857109e-03   1.08453364e-03   1.16801087e-03  -3.98012670e-03\n",
      "  -1.62913569e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   1.86562464e-01   9.90479410e-01   4.40457821e-01   5.30905664e-01\n",
      "   5.39965808e-01   9.88313913e-01   9.99846518e-01   3.53673011e-01\n",
      "   5.32826424e-01   8.26812029e-01   5.60666382e-01   1.00000000e+00\n",
      "   3.99857283e-01   5.37509955e-02   3.13661546e-01   2.75438070e-01\n",
      "   2.98594505e-01   6.81169555e-02   3.95634212e-02   5.72120190e-01\n",
      "   4.39594954e-01   9.16094184e-02   2.15958118e-01   0.00000000e+00\n",
      "   6.40235899e-04   6.30314946e-01   2.75174886e-01   8.01062822e-01\n",
      "   1.48106664e-01   7.39981592e-01   9.44535732e-01   7.98192143e-01]\n",
      "[ 0.20711176  0.02876326  0.09729876  0.10640999  0.16041027  0.02962309\n",
      "  0.02066059  0.20004292  0.18180321  0.11943899  0.08686677  0.\n",
      "  0.14787953  0.08116417  0.07663068  0.07578367  0.103834    0.17323957\n",
      "  0.09219106  0.25762835  0.20924595  0.10831314  0.10868396  0.\n",
      "  0.29125217  0.16894022  0.11097682  0.20721914  0.201811    0.          0.\n",
      "  0.          0.          0.          0.          0.          0.38986197\n",
      "  0.09709754  0.49652269  0.49861792  0.4983888   0.10755996  0.01238726\n",
      "  0.47813296  0.49926886  0.37816104  0.49563164  0.          0.4897846\n",
      "  0.22561397  0.46377069  0.44633079  0.45803583  0.2522507   0.19487445\n",
      "  0.49518585  0.49566755  0.28849235  0.41164389  0.          0.7988528\n",
      "  0.3385464   0.20283709  0.39904472  0.3548905   0.43839851  0.22872199\n",
      "  0.40118206]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print x_2, y_2, w_2\n",
    "print np.mean(x_2, axis=0)\n",
    "print np.std(x_2, axis=0)\n",
    "print np.isfinite(x_2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LeakyReLU with fix\n",
    "# https://github.com/keras-team/keras/pull/7784\n",
    "\n",
    "from keras.engine import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class MyLeakyReLU(Layer):\n",
    "    \"\"\"Leaky version of a Rectified Linear Unit.\n",
    "    It allows a small gradient when the unit is not active:\n",
    "    `f(x) = alpha * x for x < 0`,\n",
    "    `f(x) = x for x >= 0`.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as the input.\n",
    "    # Arguments\n",
    "        alpha: float >= 0. Negative slope coefficient.\n",
    "    # References\n",
    "        - [Rectifier Nonlinearities Improve Neural Network Acoustic Models](https://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.3, **kwargs):\n",
    "        super(MyLeakyReLU, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        if isinstance(alpha, dict):\n",
    "            self.alpha = K.cast_to_floatx(alpha['value'])\n",
    "        else:\n",
    "            self.alpha = K.cast_to_floatx(alpha)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return K.relu(inputs, alpha=self.alpha)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'alpha': float(self.alpha)}\n",
    "        base_config = super(MyLeakyReLU, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Create a model ####\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=nvariables, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "model.add(MyLeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(64, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "model.add(MyLeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Dense(1, kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.0000)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Set loss and optimizer\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "rmsprop = optimizers.RMSprop(lr=0.0001)\n",
    "\n",
    "# Compile\n",
    "model.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339859, 68) (226574, 68)\n",
      "(241056, 68) (0, 68)\n"
     ]
    }
   ],
   "source": [
    "print x_train_1.shape, x_test_1.shape\n",
    "print x_train_2.shape, x_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time elapsed: 6966.61199617 sec\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                4416      \n",
      "_________________________________________________________________\n",
      "my_leaky_re_lu_1 (MyLeakyReL (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "my_leaky_re_lu_2 (MyLeakyReL (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] Model is saved as model_discr.h5, model_discr.json and model_discr_weights.h5\n"
     ]
    }
   ],
   "source": [
    "#### Training ####\n",
    "\n",
    "def fit_model():\n",
    "  epochs = 20000 * 100\n",
    "  batch_size = 256//2\n",
    "  save_interval = 400\n",
    "\n",
    "  for epoch in xrange(epochs):\n",
    "    real = x_train_1[np.random.randint(0, x_train_1.shape[0], batch_size)]\n",
    "    fake = x_train_2[np.random.randint(0, x_train_2.shape[0], batch_size)]\n",
    "    \n",
    "    # Also add random noise?\n",
    "\n",
    "    ones = np.ones(batch_size)\n",
    "    zeros = np.zeros(batch_size)\n",
    "\n",
    "    x_train_batch = np.concatenate((real, fake))\n",
    "    y_train_batch = np.concatenate((ones, zeros))\n",
    "\n",
    "    d_loss = model.train_on_batch(x_train_batch, y_train_batch)\n",
    "\n",
    "    if (epoch % save_interval) == 0:\n",
    "      print \"%d/%d - loss: %f - accuracy: %f\" % (epoch, epochs, d_loss[0], d_loss[1])\n",
    "\n",
    "\n",
    "# The webpage can become very unresponsive when you train with a large dataset with the above comment.\n",
    "# So I do the following instead.\n",
    "# See issue https://github.com/jupyter/notebook/issues/1474\n",
    "\n",
    "start_time = time.time()\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = open('keras_output.txt', 'w')\n",
    "fit_model()\n",
    "sys.stdout.close()\n",
    "sys.stdout = old_stdout\n",
    "print('[INFO] Time elapsed: {0} sec'.format(time.time() - start_time))\n",
    "  \n",
    "# Store model to file\n",
    "model.summary()\n",
    "model.save('model_discr.h5')\n",
    "model.save_weights('model_discr_weights.h5')\n",
    "\n",
    "# Store model to json\n",
    "import json\n",
    "with open('model_discr.json', 'w') as outfile:\n",
    "  json.dump(model.to_json(), outfile)\n",
    "  \n",
    "print('[INFO] Model is saved as model_discr.h5, model_discr.json and model_discr_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Evaluation using Keras internal tool ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/05\n",
      "37762 37762 241056 241056\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAI8CAIAAAC4XaJJAAAABmJLR0QAAAAAAAD5Q7t/AAAgAElE\nQVR4nO3dW5aq2LYFUD03C3JqIlEyjZqcmogl836wN4mGEMprTZi9t/1hRqowfDBkucDj/X4/AEAm\n/ym9AgCwNuUHQDrKD4B0lB8A6Sg/ANJRfgCko/wASEf5AZCO8gMgHeUHQDrKD4B0lB8A6Sg/ANJR\nfgCko/wASEf5AZCO8gMgHeUHQDrKD4B0lB8A6Sg/ANJRfgCko/wASEf5AZCO8gMgHeUHQDrKD4B0\n/im9AoEcj8fSqwDAx+73+6c3UX4PRjyCjePxOPq2E29e6rZWe0OLttpbuW3ORU9f7RG3MuwJQDrK\nD4B0lB8A6Sg/ANJRfgCko/wASGfSBNOdmTjddqOLLiVh5JypRU5ic9tPe34ApKP8AEhH+QGQTq7y\nq+v6crmUXgsACsv1xWxzCri+yJv7wnbTEkbOmVrkJDa3/Uy051fXdelVACCELOV3uVy+vr5KrwUA\nIex897yu65+dF3DYE4BxDHsCwFt2Xn5VVd3/ul6vpVenV8IfkU8YOWdqkZPYXOqdl99WJBxuTRg5\nZ2qRk9hcauX34PiJ9iYuuOCCCy7Me+HTTfGnEk3xaCe/BJzwknCuTcLIOVOLnMTmtp/2/EJI+FZJ\nGDlnapGT2Fzqf0qvAIfuzn5jcy8jgG1Rfg9eDh+vU0XtUkYPYW+LoaEkRE5ihdTzbhuV34OEL9lS\ncj7UCVOLnMQKqQema4y4N+UHwChPrbOp1jfhhTKSjO4+SZha5J273//82xrlRxmGhpIQmZgMez4o\nOOEFgAEmvCxIz63GjLgkRGYu80548ST9K8gZCrxzgG04Hv/9tq97ee21cIYXAHiD8qOMXDPi/kqY\nWmRi8p3fAxNeVpPzUU2YWmTmYsLLgrxqAWKad8KLYU/KyDk0lDC1yMSk/Cgj5052wtQiE5PyAyAd\n5UcZOYeGEqYWmZhMeHlgtudqcj6qCVOLzFzM9lyQVy1ATGZ7sgc5h4YSphaZmJQfZeTcyU6YWmRi\nUn4ApKP8KCPn0FDC1CITk/KjjJxDQwlTi0xMZns+cKgDQEwOdViQnltNzt/sTZhaZObiUAf2IOfW\nIWFqkYlJ+QGQjvKjjJwz4hKmFpmYlB9l5BwaSphaZGJSfgCko/woI+fQUMLUIhOT8qOMnENDCVOL\nTEyO83vgIHeAmBzkviA9t5qcBwInTC0yc3GQO3uQc+uQMLXIxKT8AEhH+VFGzhlxCVOLTEzKjzJy\nDg0lTC0yMSk/ANJRfpSRc2goYWqRiUn5UUbOoaGEqUUmJuUHQDrKjzJyDg0lTC0yMSk/ysg5NJQw\ntcjE5PRmD5zbEyAm5/ZckJ5bTc7zHyZMLTJzcW5P9iDn1iFhapGJSfkBkI7yo4ycM+ISphaZmJQf\nZeQcGkqYWmRiUn4ApKP8KCPn0FDC1CITk/KjjJxDQwlTi0xMyg+AdJQfZeQcGkqYWmRiUn6UkXNo\nKGFqkYlJ+QGQjvKjjJxDQwlTi0xMyo8ycg4NJUwtMjEpPwDS8ZNGD/ye32py/uxLwtQiMxe/57cg\nL9nV5HyoE6YWmbn4PT8AmET5UUbOGXEJU4tMTMqPMnIODSVMLTIxKT8A0lF+lJFzaChhapGJSflR\nRs6hoYSpRSYm5QdAOsqPMnIODSVMLTIxKT/KyDk0lDC1yMSk/ABIR/lRRs6hoYSpRSYm5UcZOYeG\nEqYWmZiUHwDpKD/KyDk0lDC1yMSUrvyOx2Nd16XXgqRDQwlTi0xMucrvcrkcDgflB5Bclh+zvVwu\ndV3fbrfSK8IfOX/tOmFqkYkpRfnVdf39/V16LXiQc+uQMLXIxJRi2LOqqvv9fr/fz+dz6XUBoLwU\n5UdAOWfEJUwtMjGVL7+6rpt5KO9czVyV3cg5NJQwtcjEVP47v6+vr3Ye5kuXy6X9xq65cDqdui04\n3IhVVc26vgBsXuHy+3VPrtt8p9Opma55u92qqmpvW9d13/1UVaX8Yso5Iy5hapGJqWT5dYvtpXaW\n5vl8bncN67r++vq63W51XTfF9s6oKdHk3DokTC0yMRX4zq+u6+PxeDwefz38oG21br1VVXU6ndrx\nUgD4VPkJLwOaQc6fxyfY1duBnDPiEqYWmZgKlF971N39fr9er+9cv+8vs0/+PH6ivcm8F7ors+ML\n9/s9wmqsfKEVZH1EFjls0k83xZ8q/MVs8wXey1Hygf/VPkbd7wKnK/g1dXfRvi0HtuF4PLQbq+7l\ntddizDYz9LAnOzb689qmJUwtMjHFLb/hIc1mzotj3rcr595twtQiE1P5g9xDefmRzUsZoLh5d6nj\n7vkNH5zeTASd/QD2+yvzLoJGzqGhhKlFZi4vt8+jN9Fxy499y/mpImFqkYkpbvm9czyDU5cBMELc\n8mv9LL/2L8pvu3IODSVMLTIxhS6/vimdy03ynPEISoblHBpKmFpk5jLvQe6hy685gP12uz0dyd6e\n7Xr2JZrwAhDTvBNe4p7hpVFVVXuGz+ZnjNrTYc++5s7wsqYkMZ8kTC3ynm35DC/Ry6/bf62nH7Od\ni/ID+IDyW1r9V/XXEktRfgAfUH770PfF6QoPUcLySxLzScLUIu/ZuuU3MLdlxAPu9GYPsrxkA8j5\nUCdMLTJz6Xtgx034DD3bEwCWoPwoI+cBlAlTi0xMhj0pI+fQUMLUIu/NXqpd+QHwiV20u/J74Pf8\nVpNoRlxHwtQiM5d5x5OV3wMv2dXkfKgTphaZuZjtCQCTKD/KyDkjLmFqkYlJ+VFGzqGhhKlFJibl\nB0A6yo8ycg4NJUwtMjGZ7fnAoQ6ryfmoJkwtMnNxqMOCvGoBYnKoA3uQc2goYWqRiUn5UUbOneyE\nqUUmJuUHQDrKjzJyDg0lTC0yMSk/ysg5NJQwtcjEpPwASEf5UUbOoaGEqUUmJsf5PXCQ+2pyPqoJ\nU4vMXBzkviCvWoCYHOTOHuQcGkqYWmRiUn6UkXMnO2FqkYlJ+QGQjvKjjJxDQwlTi0xMyo8ycg4N\nJUwtMjEpPwDSUX6UkXNoKGFqkYlJ+VFGzqGhhKlFJiblB0A6yo8ycg4NJUwtMjE5vdkD5/ZcTc5H\nNWFqkZmLc3suyKsWICbn9mQPcg4NJUwtMjEpP8rIuZOdMLXIxKT8AEhH+VFGzqGhhKlFJiblRxk5\nh4YSphaZmJQfAOkoP8rIOTSUMLXIxKT8KCPn0FDC1CITk/IDIB3lRxk5h4YSphaZmJQfZeQcGkqY\nWmRiUn4ApKP8KCPn0FDC1CITk191oIycQ0MJU4u8B3usc+X3wO/5AbwQYDPo9/wWpOdWczweEz7a\nCVOLzFz8nh97kHPrkDC1yMSk/ABIR/lRRs4ZcQlTi0xMyo8ycg4NJUwtMjEpPwDSUX6UkXNoKGFq\nkYlJ+VFGzqGhhKlFJiblB0A6yo8ycg4NJUwtMjEpP8rIOTSUMLXIxKT8AEhH+VFGzqGhhKlFJiYn\nto6o++bZ6xDKXnMNS5haZGJSfuF03zk+QgIsYefDnnVdV1V1PB6Px2NVVXVdl14j/sjZ6wlTi0xM\ne/7dqbquv76+DofD6XQ6HA632+1wOJzP58vl8vL6BX+Fq2/RfhgMKO94/P3HbN+5zjLGbSf3vG1t\nPn9dr9eqqrp/GfhFROUH8GyP5bfzYc/D4dA2X7sLaPAzgpxDQwlTi0xMe57wcjqdus1HKDn3aBOm\nFpmYEo2qtV8BBhn2fPp4aNgTCMqw54zquu6bePLzatMHKi+XS9N81+t14l3N6P5X6RUpIOfQUMLU\nIhNTySkew+MDl8vl+/u7+5fT6dRtweFGbAc82x2+p8kvL1dp5T2/Xxdnzw8ob497fmW+8/t1T67b\nfKfTqTlK4Xa7dY/Vq+u6736qqmpKrr2fgSMcAEjnvrrz+Ty89HZk8nw+//zj9Xr9aEGn0+nN66/8\naDwNe/56nZ3ZcbQBCVOLvFWHw8O/d65fyLgHfL1Rte7wY7f8fl6zqqpmV+/p//b9vc+vI6s/r2/Y\nE+AwYhjTsOd07alYnv7eTlp5Rzsi+vNLvsvl4hAIgNQW2Af9XTuG+fL/Nv/r5fDmwP968rM7W303\nH/fQjb7Q7pV2/3PgOju7MMtj6IILLix04f7prf6+r+dajRFb44+UGVUbOORu+Gi8ZiRzodkrhj0B\n/tj7sOf+T28GAE/Cld/wURB7PTlnwqNiE0bOmVpkYoo44aWgl6/aFQYeE45tJoycM7XIzGXeTxXh\n9vyG52E2E0GXm6v58nvRhZYFwPv6pq6Mu7dw5ZdTwnGShJFzphaZmMKVX/ecnL9eZzcS7l8mjJwz\ntcjEFK78Wj/Lb+C4dQB4X8Ty65vSucIkz+MrSy805zhJwsg5U4vMXF5un0c/2hHLrzmA/Xa7PR3J\n3v4+w3KLLjXhJeE4ScLIOVOLzFzmnfAS7gwvjfYc1ufzufkZo/YXjpZbYWd4Afhj72d4CVp+3f5r\nPf2Y7ewKll/fop/26PdUhDl7PWFqkbdK+RVU/1X9tejiAu75Tbk+wHjKL4++L04XeoiUHxBXvPIb\nmNsyYtvo9GYPSrVLwmJLGDlnapGZS9+jOm7Cp/ILIeFbJWHknKlF3pJMB2koPwD+2m5zfyjicX4J\nJTwqNmHknKlFJiblF8KGx0nGShg5Z2qRicmw54NSv+cHwLB5d6mV3wOzPVeTMHLO1CIzl3lnexr2\nDCHhWyVh5JypRSYm5QdAOsovhITTwxJGzplaZGJSfiEkHCdJGDlnapGJSfkBkI7yCyHhOEnCyDlT\ni0xMDnV4UOo4v4TjJAkj50wtMnNxnN+CvGoBYnKc3w4lHCdJGDlnapGJyZ5fCG/ucXbfVFvfSd36\n+o+TMLXIxKT8NqP7jvLREphB4i2JYc8QEpZZwsg5U4sc3f3+8C8N5RdCwnGShJFzphaZmJQfAOko\nvxA2Nk4yh4SRc6YWmZhMeHngIPfVJIycM7XIzMVB7gvyqgWIyUHuO5RwnCRh5JypRSYm5RdCwj3O\nhJFzphaZmJQfAOkovxASjpMkjJwztcjEpPxCSDhOkjByztQiE5PyAyAd5RfCiHGSY8cyK7Wsja72\nRAlTi0xMjvML4dNxkh38wkPOoaGEqUUmJnt+AKRjz+9BqdObHY/HbJ8WE0bOmVpk5uL0Zgsq9ZJN\n+FZJGDlnapHD2eYXJbOf3kz5ASQTvJ5X4Tu/EDY6aWWKhJFzphaZmOz5hTBxnKT7Zos+5PLXVtZz\nXglTixyCPv5B+W3eDg57ABYXsJKLMuwZQsLSShg5Z2qRicmeXwj3p3GJBJ/RIg4NLS9hapGJSfmF\n0b5hfGwEWJhhT8rIOTSUMLXIxGTPb2+2MvMz8rotJ2FqkYlJ+e2KmZ/AH7YAgwx7UkbObk6YWuSS\n7vd///FI+VFGzqGhhKlFJiblB0A6yo8yAg0NrShhapGJyYSXB6V+zy+hnI9qwtQiMxe/57cgr1qA\nmOb9PT/DnpSRc2goYWqRV172v/8YZM9vzyIf8B5tfdaRMLXI6y++5NK3Q/nt1tMB75GLEBjPTt4o\nhj1TuHeUXpc/Eo6G5Uwt8hoczP455UcZcWp4TQlTi0xMyg+AdJQfZSQcDcuZWmRiUn6UkXNoKGFq\nkYlJ+QGQjvKjjJxDQwlTi0xMyo8ycg4NJUwtMjEpPwDSUX6UkXNoKGFqkYlp5+VX13VVVc3Jvaqq\nKr06/Cvn0FDC1CIT057P7Xm5XL6/vw+Hw+l0OhwOt9vteDx6XQKw5zJoBh/agE0Xnk6nuq77rr/m\no/GwuOPx8PLywst9Gp8pFj+NhKlFXmF5IU7pWW41xj3ge35dHo/Hp6p7qsOf109Yfi8vA5uh/EZt\nu/Y87Hm9Xrv/2bRgMwQKQGYpPuxfLpfD4dB8/3e9XvtmvuTZ8+v+Z6k9v5w7mglTi7zQMh7+M8Ij\nvLU9vxSvy3ZzP/CFX57ye2t9gGjiFV7BSQNPq7GlYc+6ruu6bvbJfr1aVVU/d9cGauxwOHSvf7/f\nm2XdbreqqoZvCBBUgMJ70jd7Lr5iH/aH5550D1RoPe23XS6XvhqrquplrZrw8u767G5xQSRMLfKM\n9xut/ILMmBu56HsJ7VSUviucz+d2DbtTVE6n05uLaO7her12/9jc1dMfWys/Gg+L67tcan2AaOK9\nQ7sbjYIbkHGLLnCGl8vl8vX1NXCFuq6bfb7z+dyMWLZ9ebvd3hy0bIY9n/b/brfb04goAAmtt6Na\n1/XPznu59KqqmpZ6+r99f+/TDHKez+e2CG+3m4PcB9an+59LPxQJR8NyphZ5xvs17Pnranxwq4Dl\n15bW035bew9vrvPPJZrt+aaEGyyILsCW4cmmyy/id37N/3r5zdzA/xpYVuPXa4576EZfaFu8/e92\nPSbe8/QLL8MWXB8XXEh64fFf+fXpvzD7VmLpIgt3hpd2z2zgm7nm4Ic37/Cjb/jGPejjLjxNPf25\n6NH3PP3C08r0reqUC90Pa3kutIKsj8jRIz/u7d1nvOe5ky6xlXjTuKMsdv6TRoT10Yt7NxKmFpmY\nwpXf8GTO5lgFR6mv79hRel1g147Hf/+xmHDDnmW93LL7HNd9BOYqv5xzahKmFnmMZI/Ym+b95B1u\nz2/4K7qlD9R7+b3oQstKLucDmzC1yMylb+rKuHsLV34AsLRw5dfu1Q18secULTuQ87vDhKlFJqZw\n5df6WX7vHAXBCmaZ/JJzaChhapGJKWL59U3pXGGS5/GVpRe6Lb4NhXl0Z3Wa4fmGl9vn0ZvoiOXX\nnNXsdrs9nd6sPdv1cos24WU1OT9VJEwt8pD7/fU/Xpl3wkuZWci/nqWzPYd1c1rq9nceFh1ScG7P\nTyWcxQ6z2c47vc+mz+0ZtPy6/dcaPi31dMrvU8oP/nja23vnfbGdd3pX38+/KL851X9Vfy26OOX3\nqSmPWM7iTJg6S+SBt3BfL27nnd7V94Qqvw3rG6lf6CFKXn6wK8Plt/F3elfB8hv4MnXEop3e7IFN\nOUBMfdtnv+pAAaMnHCecBJgzdcLIbII9P8abcsLrnDvZCVMnjMwmKD/m1zcfDHAYexDKj9l0O687\nAbrvyglLMWHqhJGHeCjCUH7M49MNXM4NYsLUCSOzCcrvgR+zBYhp3slTyu+BnltNztGwhKn3HNm3\nd+ua91AH5UcZu90gDkqYeueR951u15Qf6zELFAhC+bG4j2aB7tuexwB7JIzMJig/lmXD15Xw0UgY\nmU1QfgAM2eU4jfJ74FAHFpVwDDBh5F2K8CQ61GFBEZ5gdizhCyxhZBbiUAeA2LY/TrjLoc4u5Ud5\neQ6BSDgGmDHyXl7D+0jRR/mF1C2D/b7+Eh4Cse+tyUsiE5Pyi6f7ztlvE9hAAAX5JXfK2PceXp+E\nqUUmJuVHGTn3/BKmFpmYlB8A6fjO74GD3FczMAnw5USYfcg49VFkZuIg9wV5ya6m76Hu/n1/350k\nfIGJzFwc5E4iO94LhGj293FzgPKjjHeGhva3F5hwQEzkbdnumn9K+VHGiPfYDvYCN7raU4hMTMqP\nbdjfXiBQkPILb6enOps4NLTR04FuekBsnJKRnz4krbUaCZ/lLVJ+se33VGdTtg5Pt+0WYfBSjLY+\nKygcuV36im+fhM/yFik/9ibJObKBKZzhhTJWbqbjozUX/bQapRZdisjEZM+PMtYfGoqwR5hwQEzk\naIJ/NbAa5ffA6c125teesyEgoQgfBEdwerMF2fatZoUZcW/ef3dDsPShhAnnAa4RudCszj4Jn+V1\nOL0ZexBw67DCoYQBUy9tpcglZnX2Sfgsb5HyI6NtjfYAs1N+lFFwaKjgB/OEA2IiB5f2g6Dy26Zg\nX3KMMO/WYStv4A1tE+dyn3KWopVf5wOvok+GVTf0LG9oVWen/DYr0pccZa35BjY7dIwpr9WVX+cv\nn9Btftb0Wh3mIHfK2Mq+2k/3v0bcdrupeV+cZ3nKa3X37PlRxj7ekC8PjRj4xL2P1AzzLG+C8tuU\nMJ8oR9rW8NFv31QNHBoR7iDiGR/5iXc15VdK5vqFkxFPSpDnkfkov+0IXhVv2s5Xld31m+uhLzkP\ncMZHfvRdTfmVknl/4eSjZ+HDp2zlZ9l3e+MoP3jh3tnkzbj3ZsOUQc7z1m6OCS8ApGPPD3431wfq\ndwbE5hrFer6fcffC5yYOey40jGmn8InyI58Pp2zc5/vC9c0jvucaxZp0P6VmJ03fRpfeyk+vq9mH\nMY23/6T8SGmBeTfvbqe2M+Wn2KpO2VLbyvMe5ffA7/kxjhcJrW2d23ND/J7fgrxkYdjxcUfQG+Yn\nm5GF+D0/2IPnFll4i3mcr7FMrF/Tpz+w7El5k/KDYlZrkYUOW+SlGYc9P/2BZTud71N++7Kt84cx\n1tBhDB+dCaXsC2auU51NuMkSxxVooE1QfruzocmEvKFv1Othr7HvSX9nKxxhSueUU51NvolR3JyU\nH6zn+OGG/tNRr0/vnyWY7bkJyg9WdV94T2vp+59i5VMwr7m4dfYaP538wgDlB7yw0CENK48xdhe3\ndHMsHe3TYQCGKT/gtdWKaoVjBwM2h58iKkv57ULfm7nv73O9zQY2Ih8t4p1pGsvNS5zrJ1JnVGKV\nfvm+cOGJo+21Q/TSWsy1KUj5bV/fVqbv7/O+zd4pqo/u551CnTHCvD+ROsHxZeGtvMs10FhLP0GB\nv6pch/5bmfKD8u7lOthoWwSehfUpP9iMgjsHW9kvWWI9fTm3S8oPlrWDn2QbWPSMpwydyxInwJxr\n1uhWPkNkoPxgQc8bx31t+zZ6ytApHyOmzxq14xjEf0qvwHqOx+Plcim9FgCUl2XPr/mMVtd16RWJ\nYelDIJjRG4c9POyCxPhecMor6ddxxZ+7XHPtTm3o94M2tKsdU4rys8P3YJ1DIJjFG7NA7zE+tcw1\nBPrmuOISB61v6PeDjJ1Ot//yq+v6+/u79FpAICvsNKy2F7icKY+SCaLx7f87v6+vr8PhcL1eS68I\nhHA/HO6t5Rcx6X7uS6/pW4v+dOlTbstqdl5+VVVpPmBNvo3bhGLlV9f1O1/FNVcbN1Hlcrncbrfz\n+dxUIFDE8a83//7p/UTzc29vK2ueSrEfXWxeBwNLv1wuT9/VnU6nbgv+2ohfX1/tTeq67v5n3yqt\n+Wg8LK77Y9yljFiHvpu88/d3Lr9z2xGmrN5Enyad8vcp6zDxrhZ69HrX4tg9CN1IYxEFH/lxiy4z\n4eXX3uo23+l0ut1uh8PhdrtVVdXetq7rvvvpXq2729fcw+VysS8ILEQBb8N9defzeXjp7Vd05/P5\n5x+v1+s7SzmdTn2Ru3fbtfKjcXicd7Dmol8bsQ59N3nn7+9cfue2I0xZvYk+TTrl71PWYeJdrfva\n7r6VimzTKPvIj1v0ep9QmoHHpz++XHpVVc2u3tP/7fv7+0s37Dm8QkP/d8rw5sv7mTjs+c6qvrPo\ngUV8+iM7vy73/UX0rd5HcfrM+MuIU+LMx7BnBJsb9ow427NpuO4OYsOx6su633v/zXjPK6/qLMsd\nWNyMy/31UZrrYZz3yf1tEQnneJjYsgnrlV9VVe3+5jvHHvz8Wq79y3JnKTt+or1J2gvdxy3Cdcou\n4p37WWERW3wB7OPRCLs+G73w6ab4U+HO8PJyosrP63w6Y6Wp3l+vNmLfub3Jpxea52z0zVe90LOq\n7zwIH19nwrLevfmE67xzYeB+VljEmhcCrsaW3lb7urDQI/+Ocf0XcdgT2I3RH8y3K2HkLQpXfsND\nms0cTj/OAFvx0Uf4fUgYeYvCDXuW9fIjm5cyQHHz7lKH2/Mb/jKvmQi63CHqfQeRAOMkHANMGHkd\nA8f5jRCu/IA9SfjxMWHkLQpXfu8cz+DkZABMEa78Wj/L752jIIBQEo4BJoy8RRHLr29K5wqTPGc8\ngjK74/HPvym3Xf/Bn2W1+/4+b5xSD9GHq5FwDDBh5HXMe5B7xPJrTmN2u92ezmfW/M7Dz9OezciE\nl3lMOYHW0mfeenPRU1a7e9vZzxU3fVVnFGQ1OpvFguvA0uad8FLmVKTtSa77lt6ew7r5Kdq6rttf\nOFpuhbOf2HrAXL8k13fbGX/DL8YvzPWvXc+THvwFMEHCM00njFw29bhFBy2/bv+1hn+TYTrl10v5\nLSHgKsFYym9O9V/VX4suTvn1Un5LCLhKMJby27C+LwwWeoiUX8LyM+yZQcLI66Qe+E53xKKd3uxB\nwpcsa0r4AhOZufQ9sH7VAQDeovxgPQnn4otMTMoP1pNwQExkYlJ+AKSj/GA9CQfERCYmsz0f+DFb\nFpXwtSQyc5n3U4Xye+BVCxCTQx1gqxIOiIlMTMoP1pNwaEFkYlJ+AKTjOz/e0x3JmeuD7TujQzOO\nIAUYjHo+/2GAVVpawhNdJoy8RcqPNyyxvX5n6zDjFiTGxuhhmxhjlZaWsAYSRt4i5ffAoQ4AMTnU\nYUF6bjU5h4YSphaZuTjUgT3IuXVImFpkYlJ+AKSj/Cgj54HACVOLTEzKjzJyDg0lTC0yMSk/ANJR\nfpSRc2goYWqRiUn5UUbOoaGEqUUmJsf5PXCQO0BMDnJfkJ5bTc4DgROmFpm5OMidPci5dUiYWmRi\nUn4ApKP8KCPnjLiEqUUmJuVHGTmHhhKmFpmYlB8A6Sg/ysg5NJQwtcjEpPwoI+fQUMLUIhOT8gMg\nHeVHGTmHhhKmFpmYnOHlgdObrSbno5owtcjMxenNFuRVCxCT05uxBzmHhhKmFpmYlB9l5NzJTpha\nZGJSfgCko/z43PH459+k+1hsaGiO1VtIwgExkYnJhBc+NNOQzlJDQ7FHnBIOiIlMTPb8AEhH+VFG\nzqGhhKlFJiblRxk5h4YSphaZmJQfAOkoP8rIOTSUMLXIxKT8KCPn0FDC1CITk/IDIB3lRxk5h4YS\nphaZmJQfZeQcGkqYWmRiUn4ApOP0Zg/8mO1qjsdjwgc2YWqRmYsfs12Ql+xqcj7UCVOLzFz8mO0O\nJfx+POekgISpRSYm5QdAOsoPgHSUHwDpKD8A0lF+AKSj/ABIR/nNo+Dk5ryhGrEAAAWNSURBVCmL\nnrjapVIXXG1P9Jo80WvedrtP9DjKD4B0lB8A6Sg/ANJRfgCko/wASEf5AZCO3536l3OxA2zRiCJT\nfgCkY9gTgHSUHwDpKD8A0lF+AKSj/ABIR/kBkM7/XS6X0uuQXV3X//vf/w6Hw3//+9/S6zKDiXGa\nm9d1va0HZK4ncUMvhumruqGwjVle2xvKO0KTsaqq0ivyhjvlnE6np6fjer2WXqnxJsY5n88/X5/n\n83nJVZ7BvE/iJlJPj/zzHvYd+eVre9Nv9j4bqpVtrOUute+B0+nUfWtt9C0xMU73Jk/3cDqdll/9\nkeZ9Ett7iNwE0yP33UPY1Mu9tjf6Zu9zvV6VH79o3wDdV3/7x6KrNsbEOO175qnnXt5tHPM+ie2D\nELkGpkd+eeXIr/y5XttPz2n7XC+z1gV0925Lr8tbtrGW+9O3jYu8rR8wMc7ApuRlKQYx75N46Ahb\nfhMjt03w85phX/kTI7eV8PT3be0kDeh+aFN+/GLgdR95W99nepyBLX7ftqO4eZ/E9hGIXH7TIw88\nm9fr9Xw+Ryu/6ZGbD3Yvrxa27z+y3fJzqEMBzVTGl5qtw+12W3eNJpkrzjZmiP0145PYzLg+nU7B\np15Pj/z9/d3t+K6qqi6XS7TXwFzP8s+rDdzztlRV1dbJyyIMS/kV0Lzuf84f21wBNKbHad45L688\ncOdlzfUk1nXdVEL8reFckdsrXy6Xy+USOfj0yO0HmqdPNl9fXx/dD7NTfgVsa8fuV8vFuVwuzZ0H\n3CWaK3WzEdzER+YZn+iqqo7H4/f39/f399fX1/F4DPgUzxK5qqrmyf3+/j4ej1VVNdmb/+sX5Qr6\np/QK5LWzT3yzx6mqqtn0nE6nsI/VxBVrbh454E/TV7Xd6Wn2qJpn+fv7u67rmHuB05/l0+nUxOy2\n6SY+8eyYPT/CuVwux+Ox2Uycz+eYG8Tp2v3avQZ80o3ZTABp2q6dCHO73Xb5UHRfzI2m9b++vmLu\n7yah/AoI+A3WFDPGqeu6GQ1r/vN6vYbdOkxM3X7Vt6GP/xMjd/efnkqu74ux4qa/ttvU9/v98ldd\n1+1Y6C77fhMMexazsxf99DiXy6WtvfP5HG07+NLo1G26l2N9dV03Vwj4IEx/ovvOY/f9/R3z6/Ap\nkZtEPz/itGOhX19fvvkrQvkV0H6b9dMWG3GWOG3zbaX25noS277vut1uzZ038yMmrOac5oocJ9Gv\nJkZur/My8sCdswLlV8zL133Ymf2/mhKnOwa4oS3jlNTN8NfAHTY3D/hoTH/d1nUdMNeAnb1V+aPc\n8fWpNQ9+30meYp7gY8DEOM0WJFvqgfsM+1BMjDxwhpfm7wHPbTQxct/Ng5/RdJxtnbNtG2u5Py9f\n92FP5fWrj+I0J7bvbjXa7ci131pRPjAx9UvBy2965JcB23sI+ERPjNx3cvbIkUdTfryl3fluNvqb\n+DmbAe/HefqM/+Z0xxKZfjc69fAdRn4NTIzcne3SzPvv/ue6Ud41MXJ786YXu5ED7ulOofx4y8uN\nftj3/6/ej/P0tn859++n1QO9ZXTqPvFfBtMjb+5Xi6dHfvnVYOTI42yr/I5m2ZbVnem+iVmOw3YW\n500JU0+P3L3VJh60iZG7Nw81iTct5QdAOs7wAkA6yg+AdJQfAOkoPwDSUX4ApKP8AEhH+QGQjvID\nIB3lB0A6yg+AdJQfAOkoPwDSUX4ApKP8AEhH+QGQjvIDIB3lB0A6yg+AdJQfAOkoPwDSUX4ApKP8\nAEhH+QGQjvIDIB3lB0A6yg+AdJQfAOkoPwDSUX4ApKP8AEhH+QGQjvIDIB3lB0A6yg+AdJQfAOko\nPwDSUX4ApKP8AEhH+QGQjvIDIB3lB0A6yg+AdJQfAOkoPwDSUX4ApKP8AEjn/wFJ5hk3+XTY+QAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Application ####\n",
    "\n",
    "from keras.models import load_model\n",
    "import ROOT\n",
    "\n",
    "# Load model\n",
    "loaded_model = load_model('model_discr.h5', custom_objects={'MyLeakyReLU': MyLeakyReLU})\n",
    "loaded_model.load_weights('model_discr_weights.h5')\n",
    "\n",
    "ROOT.gROOT.LoadMacro(\"tdrstyle.C\")\n",
    "ROOT.gROOT.ProcessLine(\"setTDRStyle();\")\n",
    "ROOT.gStyle.SetPalette(57)  # kBird\n",
    "ROOT.gStyle.SetPadGridX(True)\n",
    "ROOT.gStyle.SetPadGridY(True)\n",
    "\n",
    "h1a = ROOT.TH1F(\"h1a\", \"h1b\", 120, -0.1, 1.1)\n",
    "h1b = ROOT.TH1F(\"h1b\", \"h1b\", 120, -0.1, 1.1)\n",
    "\n",
    "nentries_test_1 = x_test_1.shape[0]/6\n",
    "\n",
    "y_test_true_1 = np.ones(nentries_test_1)\n",
    "y_test_pred_1 = loaded_model.predict(x_test_1[:nentries_test_1, :])\n",
    "\n",
    "# Loop over events\n",
    "for i in xrange(nentries_test_1):\n",
    "  h1a.Fill(y_test_pred_1[i])\n",
    "\n",
    "\n",
    "x_test_2 = x_train_2  # no train/test split  \n",
    "\n",
    "nentries_test_2 = x_test_2.shape[0]/1\n",
    "\n",
    "y_test_true_2 = np.zeros(nentries_test_2)\n",
    "y_test_pred_2 = loaded_model.predict(x_test_2[:nentries_test_2, :])\n",
    "\n",
    "# Loop over events\n",
    "for i in xrange(nentries_test_2):\n",
    "  h1b.Fill(y_test_pred_2[i])\n",
    "\n",
    "\n",
    "# Draw\n",
    "c = ROOT.TCanvas()\n",
    "h1a.SetLineColor(632)  # kRed\n",
    "h1a.Scale(1.0/h1a.Integral())\n",
    "h1a.Draw(\"hist\")\n",
    "h1b.SetLineColor(1)  # kBlack\n",
    "h1b.Scale(1.0/h1b.Integral())\n",
    "h1b.Draw(\"same hist\")\n",
    "c.Draw()\n",
    "c.SetLogy()\n",
    "\n",
    "print len(y_test_true_1), len(y_test_pred_1), len(y_test_true_2), len(y_test_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9000053   0.92553361  0.95010857  0.9701287   0.98000636  0.98501139\n",
      "  0.99001642  0.99502145]\n",
      "[ 0.00161788  0.00199954  0.00280433  0.00411108  0.00547591  0.00658768\n",
      "  0.00989397  0.02255492]\n",
      "[ 0.98533368  0.97865057  0.96308589  0.91830695  0.85048354  0.77254385\n",
      "  0.53934497  0.13546965]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-matplotlib/1.5.2-njopjo/lib/python2.7/site-packages/matplotlib/figure.py:1742: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns1L6/0DHGWU2MEISAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7f005a4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_test_true = np.concatenate((y_test_true_1, y_test_true_2))\n",
    "y_test_pred = np.concatenate((y_test_pred_1, y_test_pred_2))\n",
    "\n",
    "fpr, tpr, thresh = roc_curve(y_test_true, y_test_pred)\n",
    "\n",
    "fig, ax = plt.subplots(tight_layout=True)\n",
    "ax.plot(fpr, tpr)\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.set_title('ROC curve')\n",
    "ax.set_xlim([0.0,1.0])\n",
    "ax.set_ylim([0.9,1.0])\n",
    "\n",
    "idx = np.searchsorted(tpr, [0.9, 0.925, 0.95, 0.97, 0.98, 0.985, 0.99, 0.995])\n",
    "print tpr[idx]\n",
    "print fpr[idx]\n",
    "print thresh[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
