{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using numpy 1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using keras 2.0.5\n",
      "[INFO] Using sklearn 0.18.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2023)\n",
    "import random\n",
    "random.seed(2023)\n",
    "print('[INFO] Using numpy {0}'.format(np.__version__))\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import initializers, regularizers, optimizers, losses\n",
    "print('[INFO] Using keras {0}'.format(keras.__version__))\n",
    "\n",
    "import sklearn\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('[INFO] Using sklearn {0}'.format(sklearn.__version__))\n",
    "\n",
    "import pandas as pd\n",
    "#import statsmodels\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Globals\n",
    "nlayers = 25  # 13 (CSC) + 9 (RPC) + 3 (GEM)\n",
    "\n",
    "infile = '../test2/histos_tba.8.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded the variables with shape (3953523, 103)\n",
      "[INFO] Loaded the parameters with shape (3953523, 3)\n"
     ]
    }
   ],
   "source": [
    "#### Load data ####\n",
    "\n",
    "try:\n",
    "    loaded = np.load(infile)\n",
    "    the_parameters = loaded['parameters']\n",
    "    the_variables = loaded['variables']\n",
    "except:\n",
    "    print('[ERROR] Failed to load data from file: {0}'.format(infile))\n",
    "\n",
    "print('[INFO] Loaded the variables with shape {0}'.format(the_variables.shape))\n",
    "print('[INFO] Loaded the parameters with shape {0}'.format(the_parameters.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "\n",
    "  def __init__(self, x, y):\n",
    "    if x is not None and y is not None:\n",
    "      assert(x.shape[1] == (nlayers * 4) + 3)\n",
    "      assert(y.shape[1] == 3)\n",
    "      assert(x.shape[0] == y.shape[0])\n",
    "\n",
    "      self.nentries = x.shape[0]\n",
    "      self.x_orig  = x\n",
    "      self.y_orig  = y\n",
    "      self.x_copy  = x.copy()\n",
    "      self.y_copy  = y.copy()\n",
    "\n",
    "      # Get views\n",
    "      self.x_phi   = self.x_copy[:, nlayers*0:nlayers*1]\n",
    "      self.x_theta = self.x_copy[:, nlayers*1:nlayers*2]\n",
    "      self.x_bend  = self.x_copy[:, nlayers*2:nlayers*3]\n",
    "      self.x_mask  = self.x_copy[:, nlayers*3:nlayers*4].astype(np.bool)  # this makes a copy\n",
    "      self.x_road  = self.x_copy[:, nlayers*4:nlayers*5]  # ipt, ieta, iphi\n",
    "      self.y_pt    = self.y_copy[:, 0]  # q/pT\n",
    "      self.y_phi   = self.y_copy[:, 1]\n",
    "      self.y_eta   = self.y_copy[:, 2]\n",
    "      \n",
    "      # Make event weight\n",
    "      #self.w       = np.ones(self.y_pt.shape, dtype=np.float32)\n",
    "      self.w       = np.abs(self.y_pt)/0.2 + 1.0\n",
    "      \n",
    "      # Subtract median phi from hit phis\n",
    "      #self.x_phi_median    = self.x_road[:, 2] * 32 - 16  # multiply by 'quadstrip' unit (4 * 8)\n",
    "      self.x_phi_median    = self.x_road[:, 2] * 16 - 8  # multiply by 'doublestrip' unit (2 * 8)\n",
    "      self.x_phi_median    = self.x_phi_median[:, np.newaxis]\n",
    "      self.x_phi          -= self.x_phi_median\n",
    "      \n",
    "      # Subtract median theta from hit thetas\n",
    "      self.x_theta_median  = np.nanmedian(self.x_theta, axis=1)\n",
    "      self.x_theta_median  = self.x_theta_median[:, np.newaxis]\n",
    "      self.x_theta        -= self.x_theta_median\n",
    "      \n",
    "      # Zones\n",
    "      self.x_ieta  = self.x_road[:, 1].astype(np.int32)\n",
    "      \n",
    "      # Standard scales\n",
    "      self.x_mean  = np.nanmean(self.x_copy, axis=0)\n",
    "      self.x_std   = np.nanstd(self.x_copy, axis=0)\n",
    "      self.x_std   = self._handle_zero_in_scale(self.x_std)\n",
    "      self.x_copy -= self.x_mean\n",
    "      self.x_copy /= self.x_std\n",
    "      \n",
    "      # Remove outlier hits by checking hit thetas\n",
    "      x_theta_tmp = np.abs(self.x_theta) > 4.0\n",
    "      self.x_phi  [x_theta_tmp] = np.nan\n",
    "      self.x_theta[x_theta_tmp] = np.nan\n",
    "      self.x_bend [x_theta_tmp] = np.nan\n",
    "      self.x_mask [x_theta_tmp] = 1.0\n",
    "      \n",
    "      ## Something wrong with GE2/1?\n",
    "      #bad_ge21 = 23\n",
    "      #self.x_phi  [:, bad_ge21] = np.nan\n",
    "      #self.x_theta[:, bad_ge21] = np.nan\n",
    "      #self.x_bend [:, bad_ge21] = np.nan\n",
    "      #self.x_mask [:, bad_ge21] = 1.0\n",
    "      \n",
    "      # Add variables: theta_median and mode variables\n",
    "      self.x_theta_median -= 3  # scaled to [0,1]\n",
    "      self.x_theta_median /= 83\n",
    "      hits_to_station = np.array((5,5,1,1,1,2,2,2,2,3,3,4,4,1,1,2,3,3,3,4,4,4,5,2,5), dtype=np.int32)  # '5' denotes ME1/1\n",
    "      assert(len(hits_to_station) == nlayers)\n",
    "      self.x_mode_vars = np.zeros((self.nentries, 5), dtype=np.float32)\n",
    "      self.x_mode_vars[:,0] = np.any(self.x_mask[:,hits_to_station == 5] == 0, axis=1)\n",
    "      self.x_mode_vars[:,1] = np.any(self.x_mask[:,hits_to_station == 1] == 0, axis=1)\n",
    "      self.x_mode_vars[:,2] = np.any(self.x_mask[:,hits_to_station == 2] == 0, axis=1)\n",
    "      self.x_mode_vars[:,3] = np.any(self.x_mask[:,hits_to_station == 3] == 0, axis=1)\n",
    "      self.x_mode_vars[:,4] = np.any(self.x_mask[:,hits_to_station == 4] == 0, axis=1)\n",
    "      \n",
    "      # Remove NaN\n",
    "      #np.nan_to_num(self.x_copy, copy=False)\n",
    "      self.x_copy[np.isnan(self.x_copy)] = 0.0\n",
    "\n",
    "  # Copied from scikit-learn\n",
    "  def _handle_zero_in_scale(self, scale):\n",
    "    scale[scale == 0.0] = 1.0\n",
    "    return scale\n",
    "\n",
    "  def get_x(self):\n",
    "    #x_new = self.x_phi\n",
    "    x_new = np.hstack((self.x_phi, self.x_theta, self.x_bend, self.x_theta_median, self.x_mode_vars))\n",
    "    return x_new\n",
    "\n",
    "  def get_x_mask(self):\n",
    "    x_mask = self.x_mask.copy()\n",
    "    return x_mask\n",
    "\n",
    "  def get_y(self):\n",
    "    y_new = self.y_pt.copy()\n",
    "    return y_new\n",
    "\n",
    "  def get_w(self):\n",
    "    w_new = self.w.copy()\n",
    "    return w_new\n",
    "  \n",
    "  def get_x_zone(self, zone):\n",
    "    x_ieta_tmp = (self.x_ieta == zone)\n",
    "    x_new = np.hstack((self.x_phi[x_ieta_tmp], self.x_theta[x_ieta_tmp], self.x_bend[x_ieta_tmp], self.x_theta_median[x_ieta_tmp], self.x_mode_vars[x_ieta_tmp]))\n",
    "    return x_new\n",
    "  \n",
    "  def get_x_mask_zone(self, zone):\n",
    "    x_ieta_tmp = (self.x_ieta == zone)\n",
    "    x_mask = self.x_mask[x_ieta_tmp]\n",
    "    return x_mask\n",
    "\n",
    "  def save_encoder(self, filepath):\n",
    "    np.savez_compressed(filepath, x_mean=self.x_mean, x_std=self.x_std)\n",
    "\n",
    "  def load_endcoder(self, filepath):\n",
    "    loaded = np.load(filepath)\n",
    "    self.x_mean = loaded['x_mean']\n",
    "    self.x_std = loaded['x_std']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs/5.0-ghjeda6/lib/python2.7/site-packages/ipykernel_launcher.py:44: RuntimeWarning: Mean of empty slice\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-numpy/1.12.1-mlhled2/lib/python2.7/site-packages/numpy-1.12.1-py2.7-linux-x86_64.egg/numpy/lib/nanfunctions.py:1423: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using 81 variables and 1 parameters\n"
     ]
    }
   ],
   "source": [
    "#### Prepare data ####\n",
    "\n",
    "# Preprocess data\n",
    "encoder = Encoder(the_variables, the_parameters)\n",
    "x, y, w, x_mask = encoder.get_x(), encoder.get_y(), encoder.get_w(), encoder.get_x_mask()\n",
    "#encoder.save_encoder('encoder.npz')\n",
    "#print('[INFO] Encoder is saved as encoder.npz')\n",
    "\n",
    "# Split dataset in training and testing\n",
    "x_train, x_test, y_train, y_test, w_train, w_test, x_mask_train, x_mask_test = train_test_split(x, y, w, x_mask, test_size=0.3)\n",
    "\n",
    "nvariables = x_train.shape[1]\n",
    "nparameters = 1\n",
    "print('[INFO] Using {0} variables and {1} parameters'.format(nvariables, nparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69595063  0.          0.         ...,  1.          1.          0.        ]\n",
      " [-0.33015883  0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.33125722 ...,  1.          1.          1.        ]\n",
      " ..., \n",
      " [ 0.92240101  0.          0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.2614204   0.         ...,  1.          1.          1.        ]\n",
      " [ 0.          0.          0.66696632 ...,  1.          1.          1.        ]] [-0.10976338 -0.03732378  0.04606546 ...,  0.1067722   0.11707978\n",
      "  0.07033174] [ 1.54881692  1.18661892  1.23032737 ...,  1.53386092  1.58539891\n",
      "  1.3516587 ]\n",
      "[ -1.16163479e-08  -1.63351732e-08   6.16444273e-09  -8.79568596e-09\n",
      "   0.00000000e+00  -8.18791008e-08   1.42959280e-07   1.23685329e-08\n",
      "   1.67215717e-08   2.30435646e-07  -9.36387821e-08   6.49591385e-08\n",
      "   2.16115367e-07   9.15457754e-09  -8.05541944e-08   9.15777250e-08\n",
      "  -8.72471517e-08   1.18372220e-07  -1.65068244e-08  -4.74757522e-09\n",
      "  -3.86881055e-07  -1.50894991e-07   6.82282177e-08  -7.64228290e-08\n",
      "   0.00000000e+00  -3.13735040e-06  -1.39440544e-07   9.14745470e-08\n",
      "   3.55130709e-07   0.00000000e+00  -6.42371674e-07   2.17294792e-06\n",
      "   3.57744852e-07  -7.32120782e-08   5.72325007e-07   1.33653191e-06\n",
      "  -1.03734988e-06   5.84144573e-07   2.83359758e-09  -2.20865326e-09\n",
      "  -7.41399546e-08  -1.01179197e-07  -1.77814812e-07  -7.01304685e-08\n",
      "  -1.67456164e-07   8.29823591e-07  -4.29457288e-08  -3.96127263e-07\n",
      "  -2.70409288e-07   0.00000000e+00  -6.09789538e-07  -1.15684065e-06\n",
      "   9.89658986e-08   5.51721087e-07   0.00000000e+00   8.82417694e-08\n",
      "   3.27862352e-07   7.63964294e-07  -7.86095654e-07   3.87029360e-07\n",
      "  -1.97373561e-06   2.09788982e-06   1.68049371e-06   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   4.17245507e-01\n",
      "   7.09960222e-01   3.00389051e-01   9.51365650e-01   9.82467294e-01\n",
      "   9.83936608e-01]\n",
      "[ 0.60055399  0.59068108  0.37518054  0.3903282   0.          0.58156157\n",
      "  0.57416964  0.35733905  0.37317061  0.73193932  0.58793187  0.67424315\n",
      "  0.64615089  0.33778793  0.34803733  0.50378847  0.66906643  0.51004124\n",
      "  0.33962953  0.63347912  0.52874434  0.41107425  0.67909759  0.67624182\n",
      "  0.          0.59710217  0.59001392  0.37484854  0.39061305  0.\n",
      "  0.57922316  0.57383871  0.35741144  0.37291867  0.7244671   0.58749181\n",
      "  0.67582595  0.64324337  0.33783507  0.34821653  0.50425774  0.67258942\n",
      "  0.50972843  0.33976164  0.63349867  0.52971441  0.41116533  0.67801434\n",
      "  0.6743477   0.          0.60019904  0.59029901  0.37511086  0.39034617\n",
      "  0.          0.58228308  0.57273251  0.35697249  0.37267894  0.7318542\n",
      "  0.58795804  0.67457533  0.64585036  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.26023671  0.44838247  0.45397133  0.21228048  0.13024597\n",
      "  0.12491786]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print x, y, w\n",
    "print np.mean(x, axis=0)\n",
    "print np.std(x, axis=0)\n",
    "print np.isfinite(x).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class Imputer(object):\n",
    "  \n",
    "  def __init__(self, x, x_mask):\n",
    "    if x is not None:\n",
    "      assert(x.shape[1] == (nlayers * 3) + 6)\n",
    "      assert(x_mask.shape[1] == nlayers)\n",
    "\n",
    "      self.nentries = x.shape[0]\n",
    "      self.x_orig      = x\n",
    "      self.x_mask_orig = x_mask\n",
    "      self.x_copy      = x.copy()\n",
    "      self.x_mask_copy = x_mask.copy()\n",
    "    \n",
    "      # Unpack variables\n",
    "      self.x_phi          = self.x_copy[:, nlayers*0:nlayers*1]\n",
    "      self.x_theta        = self.x_copy[:, nlayers*1:nlayers*2]\n",
    "      self.x_bend         = self.x_copy[:, nlayers*2:nlayers*3]\n",
    "      self.x_theta_median = self.x_copy[:, nlayers*3]\n",
    "      self.x_mode_vars    = self.x_copy[:, nlayers*3+1:nlayers*3+6]\n",
    "      \n",
    "      # https://stackoverflow.com/a/35611142\n",
    "      self.x_phi_hat = self._fill_missing_values(self.x_phi, self.x_mask_copy)\n",
    "      self.x_theta_hat = self._fill_missing_values(self.x_theta, self.x_mask_copy)\n",
    "      self.x_bend_hat = self._fill_missing_values(self.x_bend, self.x_mask_copy)\n",
    "      \n",
    "  def _fill_missing_values(self, x, x_mask):\n",
    "    #\n",
    "    svdmethod = partial(np.linalg.svd, full_matrices=False)\n",
    "    tol = 1e-5\n",
    "    maxiter = np.inf\n",
    "    \n",
    "    #\n",
    "    x_hat = x.copy()\n",
    "    valid = ~x_mask\n",
    "    x_hat[~valid] = np.nan\n",
    "    \n",
    "    # initialize the missing values to their respective column means\n",
    "    mu_hat = np.nanmean(x_hat, axis=0, keepdims=1)\n",
    "    mu_hat[np.isnan(mu_hat)] = 0.0\n",
    "    #sigma_hat = np.nanstd(x_hat, axis=0, keepdims=1)\n",
    "    #sigma_hat[np.isnan(sigma_hat)] = 0.0\n",
    "    #print mu_hat\n",
    "    #print sigma_hat\n",
    "    x_hat = np.where(valid, x_hat, mu_hat)\n",
    "    \n",
    "    halt = False\n",
    "    ii = 0\n",
    "    v_prev = 0\n",
    "\n",
    "    while not halt:\n",
    "      # SVD on filled-in data\n",
    "      U, s, Vt = svdmethod(x_hat - mu_hat)\n",
    "      S = np.diag(s)\n",
    "\n",
    "      # impute missing values\n",
    "      #x_hat[~valid] = (U.dot(np.diag(s)).dot(Vt) + mu_hat)[~valid]\n",
    "      x_hat[~valid] = (np.dot(U, np.dot(S, Vt)) + mu_hat)[~valid]\n",
    "\n",
    "      # update bias parameter\n",
    "      mu_hat = np.mean(x_hat, axis=0, keepdims=1)\n",
    "\n",
    "      # test convergence using relative change in trace norm\n",
    "      v = s.sum()\n",
    "      print('[INFO] ii={0} v={1} v_prev={2} s={3}'.format(ii, v, v_prev, s))\n",
    "      \n",
    "      if ii >= maxiter or ((v - v_prev) / v_prev) < tol:\n",
    "          halt = True\n",
    "      ii += 1\n",
    "      v_prev = v\n",
    "      \n",
    "    return x_hat\n",
    "  \n",
    "  def get_x(self):\n",
    "    x_new = np.hstack((self.x_phi_hat, self.x_theta_hat, self.x_bend_hat))\n",
    "    return x_new\n",
    "  \n",
    "  def get_x_mask(self):\n",
    "    x_mask_new = np.hstack((self.x_mask_copy, self.x_mask_copy, self.x_mask_copy))\n",
    "    return x_mask_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(x[:100000], x_mask[:100000])\n",
    "\n",
    "xx, xx_mask = imputer.get_x(), imputer.get_x_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print x[:100000].shape\n",
    "print imputer.x_phi.shape\n",
    "print imputer.x_phi\n",
    "print imputer.x_phi_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class PCA(object):\n",
    "  \n",
    "  def __init__(self, x):\n",
    "    \n",
    "    U, s, Vt = self._fit(x)\n",
    "    \n",
    "    self.components_ = Vt\n",
    "    n_samples = x.shape[0]\n",
    "    self.explained_variance_ = (s ** 2) / (n_samples - 1)\n",
    "    total_var = self.explained_variance_.sum()\n",
    "    self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
    "    self.singular_values_ = s.copy()\n",
    "    \n",
    "  def _fit(self, x):\n",
    "    #\n",
    "    svdmethod = partial(np.linalg.svd, full_matrices=False)\n",
    "    x_hat = x.copy()\n",
    "    mu_hat = np.mean(x_hat, axis=0, keepdims=1)\n",
    "    \n",
    "    #\n",
    "    U, s, Vt = svdmethod(x_hat - mu_hat)\n",
    "    S = np.diag(s)\n",
    "\n",
    "    # flip eigenvectors' sign to enforce deterministic output\n",
    "    U, Vt = self._svd_flip(U, Vt)\n",
    "    return U, s, Vt    \n",
    "\n",
    "  # Copied from scikit-learn\n",
    "  def _svd_flip(self, u, v, u_based_decision=True):\n",
    "    if u_based_decision:\n",
    "        # columns of u, rows of v\n",
    "        max_abs_cols = np.argmax(np.abs(u), axis=0)\n",
    "        signs = np.sign(u[max_abs_cols, xrange(u.shape[1])])\n",
    "        u *= signs\n",
    "        v *= signs[:, np.newaxis]\n",
    "    else:\n",
    "        # rows of v, columns of u\n",
    "        max_abs_rows = np.argmax(np.abs(v), axis=1)\n",
    "        signs = np.sign(v[xrange(v.shape[0]), max_abs_rows])\n",
    "        u *= signs\n",
    "        v *= signs[:, np.newaxis]\n",
    "    return u, v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(xx)\n",
    "print pca.explained_variance_.shape, pca.explained_variance_, pca.explained_variance_ratio_, pca.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for v in pca.explained_variance_ratio_:\n",
    "  print v\n",
    "print pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx_transformed = np.dot(pca.components_, xx.T).T\n",
    "xx_transformed /= pca.singular_values_\n",
    "\n",
    "print xx_transformed.shape, xx_transformed\n",
    "print pca.singular_values_.shape, 1.0 / pca.singular_values_\n",
    "print np.mean(xx_transformed, axis=1), np.std(xx_transformed, axis=1)\n",
    "\n",
    "plt.hist(xx_transformed[:,0], bins=40)\n",
    "\n",
    "#fig, axs = plt.subplots(76/4, 4, figsize=(4*4,4*76/4), tight_layout=True)\n",
    "#for i in xrange(75):\n",
    "#  hist = axs[(i/4, i%4)].hist(xx_transformed[:,i], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  from sklearn.decomposition import PCA as SL_PCA\n",
    "  sl_pca = SL_PCA()\n",
    "  sl_pca.fit(xx)\n",
    "\n",
    "  print sl_pca.explained_variance_, sl_pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  import scipy.linalg as LA\n",
    "  xx_ = xx - xx.mean(0)\n",
    "  e_values, e_vectors = LA.eigh(np.cov(xx_.T))\n",
    "  print e_values, e_vectors\n",
    "\n",
    "  idx = np.argsort(e_values)[::-1]\n",
    "  e_vectors = e_vectors[:, idx]\n",
    "  e_values = e_values[idx]\n",
    "\n",
    "  n_samples = x.shape[0]\n",
    "  explained_variance_ = e_values / (n_samples - 1)\n",
    "  total_var = explained_variance_.sum()\n",
    "  explained_variance_ratio_ = explained_variance_ / total_var\n",
    "  print explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class APCA(object):\n",
    "  \n",
    "  def __init__(self, x, x_mask):\n",
    "    \n",
    "    #w, v = self._fit(x, x_mask)\n",
    "    #s = np.sqrt(w)\n",
    "    # Vt = v.T\n",
    "    \n",
    "    U, s, Vt = self._fit(x, x_mask)\n",
    "    \n",
    "    self.components_ = Vt\n",
    "    n_samples = x.shape[0]\n",
    "    self.explained_variance_ = (s ** 2) / (n_samples - 1)\n",
    "    total_var = self.explained_variance_.sum()\n",
    "    self.explained_variance_ratio_ = self.explained_variance_ / total_var\n",
    "    self.singular_values_ = s.copy()\n",
    "    \n",
    "  def _fit(self, x, x_mask):\n",
    "    x_copy = x.copy()\n",
    "    x_mask_copy = x_mask.copy()\n",
    "    \n",
    "    x_copy[x_mask_copy] = np.nan\n",
    "    x_copy[np.abs(x_copy) > 4.0] = np.nan\n",
    "    x_copy[:, np.nanstd(x_copy, axis=0) == 0] = np.nan\n",
    "    x_copy -= np.nanmean(x_copy, axis=0)\n",
    "    \n",
    "    df = pd.DataFrame(x_copy)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df_corr = df.corr()\n",
    "    #df_cov = df.cov()\n",
    "    #print df\n",
    "    #print df_corr\n",
    "    \n",
    "    df_corr_v = df_corr.values\n",
    "    df_corr_v[np.isnan(df_corr_v)] = 0.0\n",
    "    \n",
    "    #L = np.linalg.cholesky(df_corr_v)  # check if matrix is positive definite\n",
    "    \n",
    "    #q, r = np.linalg.qr(df_corr_v)\n",
    "    \n",
    "    #w, v = np.linalg.eig(df_corr_v)  # get eigenvalues and eigenvectors\n",
    "    #ind = np.argsort(w)[::-1]  # sort by largest eigenvalues\n",
    "    #v = v[:, ind]\n",
    "    #w = w[ind]\n",
    "    \n",
    "    U, s, Vt = np.linalg.svd(df_corr_v)\n",
    "    return U, s, Vt\n",
    "  \n",
    "  def transform(self, x, x_mask):\n",
    "    x_copy = x.copy()\n",
    "    x_mask_copy = x_mask.copy()\n",
    "    \n",
    "    x_copy[x_mask_copy] = np.nan\n",
    "    x_copy[np.abs(x_copy) > 4.0] = np.nan\n",
    "    x_mask_copy[:, np.nanstd(x_copy, axis=0) == 0] = np.nan\n",
    "    x_copy[:, np.nanstd(x_copy, axis=0) == 0] = np.nan\n",
    "    x_copy -= np.nanmean(x_copy, axis=0)\n",
    "    \n",
    "    df = pd.DataFrame(x_copy)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    #print df\n",
    "    \n",
    "    df_v = df.values\n",
    "    df_v[np.isnan(df_v)] = 0.0\n",
    "    \n",
    "    df_mask = pd.DataFrame(x_mask_copy)\n",
    "    df_mask = df_mask.dropna(axis=1, how='all')\n",
    "    df_mask_v = df_mask.values\n",
    "    \n",
    "    #df_transformed = np.dot(self.components_, df_v.T).T\n",
    "    df_transformed = np.dot(df_v, self.components_)\n",
    "    return df_transformed, df_mask_v\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apca = APCA(xx, xx_mask)\n",
    "print apca.explained_variance_.shape, apca.explained_variance_, apca.explained_variance_ratio_, apca.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx_transformed, xx_transformed_mask = apca.transform(xx, xx_mask)\n",
    "#xx_transformed /= apca.singular_values_\n",
    "\n",
    "print xx_transformed.shape, xx_transformed\n",
    "print apca.singular_values_.shape, 1.0 / apca.singular_values_\n",
    "print np.mean(xx_transformed, axis=1), np.std(xx_transformed, axis=1)\n",
    "\n",
    "#plt.hist(xx_transformed[:,1][~xx_mask[:,1]], bins=40)\n",
    "#print np.mean(xx_transformed[:,1][~xx_mask[:,1]]), np.std(xx_transformed[:,1][~xx_mask[:,1]])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(76/4, 4, figsize=(4*4,4*76/4), tight_layout=True)\n",
    "for i in xrange(58):\n",
    "  hist = axs[(i/4, i%4)].hist(xx_transformed[:,i][xx_transformed_mask[:,i]], bins=40)\n",
    "  print np.mean(xx_transformed[:,i][xx_transformed_mask[:,i]]), np.std(xx_transformed[:,i][xx_transformed_mask[:,i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_copy = xx.copy()\n",
    "\n",
    "x_copy[np.abs(x_copy) > 4.0] = np.nan\n",
    "\n",
    "x_copy[:, np.sum(x_copy, axis=0) == 0] = np.nan\n",
    "    \n",
    "x_copy -= np.nanmean(x_copy, axis=0)\n",
    "    \n",
    "df = pd.DataFrame(x_copy)\n",
    "\n",
    "\n",
    "print x_copy\n",
    "print df\n",
    "\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx_transformed = np.dot(pca.components_, xx.T).T\n",
    "xx_transformed /= pca.singular_values_\n",
    "\n",
    "print xx_transformed.shape, xx_transformed\n",
    "print pca.singular_values_.shape, 1.0 / pca.singular_values_\n",
    "print np.mean(xx_transformed, axis=1), np.std(xx_transformed, axis=1)\n",
    "\n",
    "plt.hist(xx_transformed[:,0], bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### RETRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zone = 5\n",
    "x, x_mask = encoder.get_x_zone(zone), encoder.get_x_mask_zone(zone)\n",
    "print x.shape, x_mask.shape\n",
    "print (encoder.x_orig[:, 101]==5).sum()\n",
    "\n",
    "x, x_mask = x[:100000,:75], x_mask[:100000]\n",
    "\n",
    "#print encoder.x_orig[:, 0:2], encoder.x_orig[:, 101]\n",
    "print encoder.x_orig[encoder.x_orig[:, 101]==5][:, 0:2][:10]\n",
    "print encoder.x_orig[encoder.x_orig[:, 101]==5][:, 75+0:75+2][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_copy = x.copy()\n",
    "x_mask_copy = x_mask.copy()\n",
    "    \n",
    "x_copy[np.hstack((x_mask_copy, x_mask_copy, x_mask_copy))] = np.nan\n",
    "x_copy[np.abs(x_copy) > 4.0] = np.nan\n",
    "x_copy[:, np.nanstd(x_copy, axis=0) == 0] = np.nan\n",
    "x_copy -= np.nanmean(x_copy, axis=0)\n",
    "    \n",
    "df = pd.DataFrame(x_copy)\n",
    "#df = df.dropna(axis=1, how='all')\n",
    "\n",
    "df_corr = df.corr()\n",
    "#df_corr = df.cov()\n",
    "print df\n",
    "print df_corr\n",
    "    \n",
    "df_v = df.values\n",
    "df_v[np.isnan(df_v)] = 0.0\n",
    "df_corr_v = df_corr.values\n",
    "df_corr_v[np.isnan(df_corr_v)] = 0.0\n",
    "    \n",
    "#L = np.linalg.cholesky(df_corr_v)  # check if matrix is positive definite\n",
    "\n",
    "#q, r = np.linalg.qr(df_corr_v)  # QR eigendecomposition\n",
    "\n",
    "#w, v = np.linalg.eig(df_corr_v)  # get eigenvalues and eigenvectors\n",
    "#ind = np.argsort(w)[::-1]  # sort by largest eigenvalues\n",
    "#v = v[:, ind]\n",
    "#w = w[ind]\n",
    "\n",
    "U, s, Vt = np.linalg.svd(df_corr_v)\n",
    "print U.shape, s.shape, Vt.shape, np.isfinite(Vt).all()\n",
    "print s\n",
    "print Vt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_transformed = np.dot(Vt, df_v.T).T\n",
    "print x_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print xx_transformed.shape, xx_transformed\n",
    "#print apca.singular_values_.shape, 1.0 / apca.singular_values_\n",
    "#print np.mean(xx_transformed, axis=1), np.std(xx_transformed, axis=1)\n",
    "\n",
    "print x_transformed.shape, x_mask.shape, s.shape, np.isfinite(x_transformed).all()\n",
    "#print np.mean(x_transformed[:,1][~x_mask[:,1]]), np.std(x_transformed[:,1][~x_mask[:,1]]), s\n",
    "print np.mean(x_transformed[:,1]), np.std(x_transformed[:,1]), s\n",
    "plt.hist(x_transformed[:,1], bins=40)\n",
    "\n",
    "fig, axs = plt.subplots(76/4, 4, figsize=(4*4,4*76/4), tight_layout=True)\n",
    "for i in xrange(75):\n",
    "  hist = axs[(i/4, i%4)].hist(x_transformed[:,i], bins=40)\n",
    "  print np.mean(x_transformed[:,i]), np.std(x_transformed[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BPCA(object):\n",
    "  \n",
    "  def __init__(self, encoder):\n",
    "    \n",
    "    nentries = 1000000\n",
    "    nvariables = 75\n",
    "    \n",
    "    self.Vt_all = []\n",
    "    self.v_k_all = []\n",
    "    self.v_n_all = []\n",
    "    self.v_mean_all = []\n",
    "    self.v_std_all = []\n",
    "    \n",
    "    for zone in xrange(6):\n",
    "      x, x_mask = encoder.get_x_zone(zone), encoder.get_x_mask_zone(zone)\n",
    "      #print x.shape, x_mask.shape\n",
    "      #print (encoder.x_orig[:, 101]==zone).sum()\n",
    "      \n",
    "      x, x_mask = x[:nentries,:nvariables], x_mask[:nentries]\n",
    "      \n",
    "      U, s, Vt, v_k, v_n, v_mean, v_std = self._fit(x, x_mask)\n",
    "      self.Vt_all.append(Vt)\n",
    "      self.v_k_all.append(v_k)\n",
    "      self.v_n_all.append(v_n)\n",
    "      self.v_mean_all.append(v_mean)\n",
    "      self.v_std_all.append(v_std)\n",
    "      \n",
    "    print self.v_k_all, self.v_n_all\n",
    "    \n",
    "    self.chi2_all = []\n",
    "    self.ndof_all = []\n",
    "    self.ndof_mask_all = []\n",
    "    \n",
    "    for iz, zone in enumerate(xrange(6)):\n",
    "      x, x_mask = encoder.get_x_zone(zone), encoder.get_x_mask_zone(zone)\n",
    "      x = x[:,:nvariables]\n",
    "      \n",
    "      Vt = self.Vt_all[iz]\n",
    "      v_k = self.v_k_all[iz]\n",
    "      v_n = self.v_n_all[iz]\n",
    "      v_mean = self.v_mean_all[iz]\n",
    "      v_std = self.v_std_all[iz]\n",
    "      \n",
    "      chi2, ndof, ndof_mask = self._transform(x, x_mask, Vt, v_k, v_n, v_mean, v_std)\n",
    "      self.chi2_all.append(chi2)\n",
    "      self.ndof_all.append(ndof)\n",
    "      self.ndof_mask_all.append(ndof_mask)\n",
    "  \n",
    "  def _fit(self, x, x_mask):\n",
    "    x_copy = x.copy()\n",
    "    x_mask_copy = x_mask.copy()\n",
    "    \n",
    "    x_copy[np.hstack((x_mask_copy, x_mask_copy, x_mask_copy))] = np.nan\n",
    "    #x_copy[x_mask_copy] = np.nan\n",
    "    #x_copy[np.abs(x_copy) > 4.0] = np.nan\n",
    "    x_copy[:, np.nanstd(x_copy, axis=0) == 0] = np.nan\n",
    "    x_mean = np.nanmean(x_copy, axis=0)\n",
    "    \n",
    "    df = pd.DataFrame(x_copy - x_mean)\n",
    "    #df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    df_corr = df.corr()\n",
    "    #df_corr = df.cov()\n",
    "    #print df\n",
    "    #print df_corr\n",
    "    \n",
    "    df_v = df.values\n",
    "    df_v[np.isnan(df_v)] = 0.0\n",
    "    df_corr_v = df_corr.values\n",
    "    df_corr_v[np.isnan(df_corr_v)] = 0.0\n",
    "    \n",
    "    #L = np.linalg.cholesky(df_corr_v)  # check if matrix is positive definite\n",
    "\n",
    "    #q, r = np.linalg.qr(df_corr_v)  # QR eigendecomposition\n",
    "\n",
    "    #w, v = np.linalg.eig(df_corr_v)  # get eigenvalues and eigenvectors\n",
    "    #ind = np.argsort(w)[::-1]  # sort by largest eigenvalues\n",
    "    #v = v[:, ind]\n",
    "    #w = w[ind]\n",
    "\n",
    "    U, s, Vt = np.linalg.svd(df_corr_v)\n",
    "    \n",
    "    assert all(s[i] >= s[i+1] for i in xrange(len(s)-1))  # check is sorted\n",
    "    assert all(s[i] >= 0 for i in xrange(len(s)))  # check non-negative s\n",
    "    #print U.shape, s.shape, Vt.shape, np.isfinite(Vt).all()\n",
    "    #print Vt\n",
    "    \n",
    "    n_samples = x_copy.shape[0]\n",
    "    explained_variance_ = (s ** 2) / (n_samples - 1)\n",
    "    total_var = explained_variance_.sum()\n",
    "    explained_variance_ratio_ = explained_variance_ / total_var\n",
    "    print explained_variance_ratio_, s\n",
    "    \n",
    "    ratio_cumsum_ = explained_variance_ratio_.cumsum()\n",
    "    v_k = np.searchsorted(ratio_cumsum_, 0.9) + 1\n",
    "    \n",
    "    #Vt = Vt / s[:, np.newaxis] * np.sqrt(n_samples)  # whiten\n",
    "    \n",
    "    x_copy[np.isnan(x_copy)] = 0.0\n",
    "    #x_transformed = np.dot(Vt, x_copy.T).T\n",
    "    x_transformed = np.dot(x_copy, Vt.T)\n",
    "    \n",
    "    v_n = s.size - np.searchsorted(s[::-1], 1e-04, side='right')\n",
    "    v_mean = np.mean(x_transformed, axis=0)\n",
    "    v_std = np.std(x_transformed, axis=0)\n",
    "    v_std[v_std == 0.0] = 1.0\n",
    "    #print s, v_n, v_mean, v_std\n",
    "    #print np.sqrt(s), np.sqrt(s)/v_std\n",
    "    return U, s, Vt, v_k, v_n, v_mean, v_std\n",
    "  \n",
    "  def _transform(self, x, x_mask, Vt, v_k, v_n, v_mean, v_std):\n",
    "    x_copy = x.copy()\n",
    "    x_mask_copy = x_mask.copy()\n",
    "    \n",
    "    x_transformed = np.dot(x_copy, Vt.T)\n",
    "    #print x_transformed\n",
    "    \n",
    "    x_transformed -= v_mean\n",
    "    x_transformed /= v_std\n",
    "    x_transformed **= 2\n",
    "    x_transformed = x_transformed[:,v_k:v_n]\n",
    "    #print x_transformed\n",
    "    \n",
    "    chi2 = np.sum(x_transformed, axis=1)\n",
    "    ndof = np.sum(x_copy != 0.0, axis=1) - v_k\n",
    "    ndof_mask = np.sum(~x_mask_copy, axis=1)\n",
    "    return chi2, ndof, ndof_mask\n",
    "\n",
    "  def save_bpca(self, filepath):\n",
    "    np.savez_compressed(filepath, \n",
    "                        Vt_all=np.array(self.Vt_all), \n",
    "                        v_k_all=np.array(self.v_k_all),\n",
    "                        v_n_all=np.array(self.v_n_all),\n",
    "                        v_mean_all=np.array(self.v_mean_all),\n",
    "                        v_std_all=np.array(self.v_std_all))\n",
    "\n",
    "  def load_bpca(self, filepath):\n",
    "    loaded = np.load(filepath)\n",
    "    self.Vt_all = loaded['Vt_all']\n",
    "    self.v_k_all = loaded['v_k_all']\n",
    "    self.v_n_all = loaded['v_n_all']\n",
    "    self.v_mean_all = loaded['v_mean_all']\n",
    "    self.v_std_all = loaded['v_std_all']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bpca = BPCA(encoder)\n",
    "bpca.save_bpca('bpca.npz')\n",
    "print('[INFO] BPCA is saved as bpca.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bpca.chi2_all[0].shape, np.isfinite(bpca.chi2_all[0]).all()\n",
    "print bpca.ndof_all[0].shape, np.isfinite(bpca.ndof_all[0]).all()\n",
    "print bpca.v_n_all\n",
    "\n",
    "print bpca.chi2_all[0], bpca.ndof_all[0], bpca.ndof_mask_all[0]\n",
    "y = bpca.chi2_all[0]/bpca.ndof_all[0]\n",
    "y = y[bpca.ndof_mask_all[0] == 7]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.hist(y, bins=40, range=(0,15), normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "fig, ax = plt.subplots(6/3,3, figsize=(5*3,5*6/3), tight_layout=True)\n",
    "for i in xrange(6):\n",
    "  _ = ax[i/3,i%3].hist(bpca.ndof_mask_all[i], bins=15, range=(0,15), normed=True, alpha=0.6)\n",
    "\n",
    "\n",
    "df = 4\n",
    "x = np.linspace(chi2.ppf(0.01, df), chi2.ppf(0.99, df), 40)\n",
    "\n",
    "fig, ax = plt.subplots(6/3,3, figsize=(5*3,5*6/3), tight_layout=True)\n",
    "for i in xrange(6):\n",
    "  y = bpca.chi2_all[i]/(bpca.ndof_all[i])\n",
    "  y = y[bpca.ndof_mask_all[i] == df+2]\n",
    "  _ = ax[i/3,i%3].hist(y, bins=40, range=(0,15), normed=True, alpha=0.6)\n",
    "  ax[i/3,i%3].plot(x, chi2.pdf(x, df), 'r-', lw=5, alpha=0.6, label='chi2 pdf')\n",
    "  print i, np.percentile(y, 98.)\n",
    "  \n",
    "\n",
    "df = 5\n",
    "x = np.linspace(chi2.ppf(0.01, df), chi2.ppf(0.99, df), 40)\n",
    "\n",
    "fig, ax = plt.subplots(6/3,3, figsize=(5*3,5*6/3), tight_layout=True)\n",
    "for i in xrange(6):\n",
    "  y = bpca.chi2_all[i]/(bpca.ndof_all[i])\n",
    "  y = y[bpca.ndof_mask_all[i] == df+2]\n",
    "  _ = ax[i/3,i%3].hist(y, bins=40, range=(0,15), normed=True, alpha=0.6)\n",
    "  ax[i/3,i%3].plot(x, chi2.pdf(x, df), 'r-', lw=5, alpha=0.6, label='chi2 pdf')\n",
    "  print i, np.percentile(y, 98.)\n",
    "\n",
    "  \n",
    "df = 6\n",
    "x = np.linspace(chi2.ppf(0.01, df), chi2.ppf(0.99, df), 40)\n",
    "\n",
    "fig, ax = plt.subplots(6/3,3, figsize=(5*3,5*6/3), tight_layout=True)\n",
    "for i in xrange(6):\n",
    "  y = bpca.chi2_all[i]/bpca.ndof_all[i]\n",
    "  y = y[bpca.ndof_mask_all[i] == df+2]\n",
    "  _ = ax[i/3,i%3].hist(y, bins=40, range=(0,15), normed=True, alpha=0.6)\n",
    "  ax[i/3,i%3].plot(x, chi2.pdf(x, df), 'r-', lw=5, alpha=0.6, label='chi2 pdf')\n",
    "  print i, np.percentile(y, 98.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### RETRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "class CPCA(object):\n",
    "  \n",
    "  def __init__(self, encoder):\n",
    "    \n",
    "    #self.x_orig = encoder.x_orig\n",
    "    #self.y_orig = encoder.y_orig\n",
    "    #self.x_copy = encoder.x_copy\n",
    "    #self.y_copy = encoder.y_copy\n",
    "    \n",
    "    self.x_ieta = encoder.x_ieta\n",
    "    self.x_phi  = encoder.x_phi\n",
    "    self.x_mask = encoder.x_mask\n",
    "    \n",
    "    self.y_pt   = encoder.y_pt.reshape(-1,1)\n",
    "    self.y_phi  = encoder.y_phi.reshape(-1,1)\n",
    "    #print self.y_pt.flags['OWNDATA'], self.y_phi.flags['OWNDATA']  # False: they are np views\n",
    "    \n",
    "    #self.x_phi   = self.x_copy[:, nlayers*0:nlayers*1]\n",
    "    #self.x_mask  = self.x_orig[:, nlayers*3:nlayers*4].astype(np.bool)  # this makes a copy\n",
    "    \n",
    "    zone = 5\n",
    "    x_ieta_tmp = (self.x_ieta == zone)\n",
    "    x = self.x_phi[x_ieta_tmp]\n",
    "    x_mask = self.x_mask[x_ieta_tmp]\n",
    "    \n",
    "    #x = x[:20000,:13]  # CSC only\n",
    "    #x_mask = x_mask[:20000,:13]  # CSC only\n",
    "    \n",
    "    #y = self.y_pt[:, np.newaxis][x_ieta_tmp]\n",
    "    y = np.hstack((self.y_pt, self.y_phi))\n",
    "    y = y[x_ieta_tmp]\n",
    "    #y = y[:20000]\n",
    "    \n",
    "    #print x\n",
    "    #print x_mask\n",
    "    \n",
    "    self._fill_missing_values(x, x_mask, y)\n",
    "    \n",
    "  def _fill_missing_values(self, x, x_mask, y):\n",
    "    svdmethod = partial(np.linalg.svd, full_matrices=False)\n",
    "    \n",
    "    x_hat = x.copy()\n",
    "    valid = ~x_mask.copy()\n",
    "    x_hat[~valid] = np.nan\n",
    "    \n",
    "    mu_hat = np.nanmean(x_hat, axis=0, keepdims=1)\n",
    "    sigma_hat = np.nanstd(x_hat, axis=0, keepdims=1)\n",
    "    \n",
    "    print x_hat\n",
    "    print mu_hat, sigma_hat\n",
    "     \n",
    "    tmp = (x_mask[:,0] == 0) & (x_mask[:,1] == 0)\n",
    "    print tmp.shape\n",
    "    print x_hat[tmp].shape\n",
    "    print x_hat[tmp]\n",
    "    \n",
    "    print x.shape, y.shape\n",
    "    c = np.cov(x[:,0][valid[:,0]], y[:,0][valid[:,0]])\n",
    "    print c\n",
    "    \n",
    "    d = np.cov(x[:,1][valid[:,1]], y[:,0][valid[:,1]])\n",
    "    print d\n",
    "    \n",
    "    #reg = linear_model.LinearRegression()\n",
    "    #reg.fit(x[:,0][valid[:,0]].reshape(-1,1), y[:,0][valid[:,0]])\n",
    "    #print reg.intercept_, reg.coef_\n",
    "    \n",
    "    #reg = linear_model.LinearRegression()\n",
    "    #reg.fit(x[:,1][valid[:,1]].reshape(-1,1), y[:,0][valid[:,1]])\n",
    "    #print reg.intercept_, reg.coef_\n",
    "    \n",
    "    xmin, xmax = -4, 4\n",
    "    ymin, ymax = -0.2, 0.2\n",
    "    #_ = plt.hist2d(x[:,0][valid[:,0]], y[:,0][valid[:,0]], bins=40)\n",
    "    #_ = plt.hist2d(x[:,1][valid[:,1]], y[:,0][valid[:,1]], bins=40)\n",
    "    _ = plt.hist(x[:,0][valid[:,0]], bins=100)\n",
    "    #_ = plt.hist2d(x[:,9][valid[:,9]], y[:,0][valid[:,9]], bins=40, range=[[xmin,xmax],[ymin,ymax]])\n",
    "    \n",
    "    \n",
    "    #print x[0,0], x[0,1], y[0,0]\n",
    "    #print x[1,0], x[1,1], y[1,0]\n",
    "    \n",
    "    # Fill column 0\n",
    "    #x_hat[:,0][~valid[:,0]] = ((x_hat[:,1][~valid[:,0]] - mu_hat[:,1]) / sigma_hat[:,1]) * sigma_hat[:,0] + mu_hat[:,0]\n",
    "    #x_hat[:,0][~valid[:,0]] = ((x_hat[:,1][~valid[:,0]] ) / sigma_hat[:,1]) * sigma_hat[:,0] \n",
    "    #print x_hat\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(np.hstack((x[:,0][valid[:,0]][:,np.newaxis], y[:,0][valid[:,0]][:,np.newaxis])))\n",
    "    df_corr = df.cov()\n",
    "    print df_corr.values\n",
    "    \n",
    "    df = pd.DataFrame(np.hstack((x[:,1][valid[:,1]][:,np.newaxis], y[:,0][valid[:,1]][:,np.newaxis])))\n",
    "    df_corr = df.cov()\n",
    "    print df_corr.values\n",
    "    \n",
    "    df = pd.DataFrame(np.hstack((x[:,0][:,np.newaxis], y[:,0][:,np.newaxis])))\n",
    "    df_corr = df.cov()\n",
    "    print df_corr.values\n",
    "    \n",
    "    df = pd.DataFrame(np.hstack((x[:,1][:,np.newaxis], y[:,1][:,np.newaxis])))\n",
    "    df_corr = df.cov()\n",
    "    print df_corr.values\n",
    "     \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc630/external/py2-pippkgs/5.0-ghjeda6/lib/python2.7/site-packages/ipykernel_launcher.py:50: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        nan -0.77399492         nan ...,         nan  0.45591247\n",
      "          nan]\n",
      " [        nan  0.79929847         nan ...,         nan -0.16192777\n",
      "          nan]\n",
      " [ 0.94457024         nan         nan ...,         nan -0.09327886\n",
      "          nan]\n",
      " ..., \n",
      " [ 0.51227087         nan         nan ...,         nan -1.12301266\n",
      "          nan]\n",
      " [        nan  0.46312466         nan ...,         nan -0.91706586\n",
      "          nan]\n",
      " [        nan -0.69331324         nan ...,         nan -0.43652344\n",
      "          nan]]\n",
      "[[-0.01231337 -0.00233619         nan         nan         nan -0.02325367\n",
      "  -0.03445            nan         nan -0.01737054         nan -0.01505584\n",
      "          nan         nan         nan         nan -0.01534533         nan\n",
      "          nan -0.00763695         nan         nan         nan -0.03516305\n",
      "   0.        ]] [[ 0.65478247  0.67894173         nan         nan         nan  0.75456977\n",
      "   0.78634882         nan         nan  0.92494243         nan  1.0035454\n",
      "          nan         nan         nan         nan  0.96081811         nan\n",
      "          nan  1.0105871          nan         nan         nan  0.7775383\n",
      "   0.        ]]\n",
      "(629004,)\n",
      "(6525, 25)\n",
      "[[-0.71811986 -0.69331324         nan ...,         nan -0.91706586\n",
      "          nan]\n",
      " [-1.05065787 -1.02948701         nan ...,         nan -0.16192777\n",
      "          nan]\n",
      " [-0.61835843 -0.65297234         nan ...,         nan -0.36787453\n",
      "          nan]\n",
      " ..., \n",
      " [ 1.11083925  1.08168447         nan ...,         nan -0.64247024\n",
      "          nan]\n",
      " [ 0.68962443  0.65138197         nan ...,         nan  0.31861463\n",
      "          nan]\n",
      " [-0.19714361 -0.23611683         nan ...,         nan -0.43652344\n",
      "          nan]]\n",
      "(629004, 25) (629004, 2)\n",
      "[[ 0.42875702  0.07135212]\n",
      " [ 0.07135212  0.01333866]]\n",
      "[[ 0.46091314  0.07333673]\n",
      " [ 0.07333673  0.01342878]]\n",
      "[[ 0.42875702  0.07135212]\n",
      " [ 0.07135212  0.01333866]]\n",
      "[[ 0.46091314  0.07333673]\n",
      " [ 0.07333673  0.01342878]]\n",
      "[[ 0.21417273  0.03563966]\n",
      " [ 0.03563966  0.01336885]]\n",
      "[[ 0.23550048 -0.01572921]\n",
      " [-0.01572921  3.28650796]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c4f8d3790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpca = CPCA(encoder)\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
